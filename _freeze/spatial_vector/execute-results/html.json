{
  "hash": "bed1127d26569f58821ab505d8c40b58",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Vector Data\"\nengine: knitr\n---\n\n\n\n\n## Library Loading\n\nBefore we can dive into \"actual\" spatial work we'll need to load some libraries.\n\n:::panel-tabset\n## [{{< fa brands r-project >}} R]{.r}\n\nLoad `sf` to work with vector data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load needed libraries\nlibrary(sf)\n```\n:::\n\n\n## [{{< fa brands python >}} Python]{.py}\n\nLoad the `geopandas` library to work with vector data. We'll also load the `os` library to deal with file path issues.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Load needed libraries\nimport os\nimport geopandas as gpd\n```\n:::\n\n:::\n\n## Loading Vector Data\n\nTo demonstrate vector data operations we'll use data on the counties in North Carolina (USA). Note that some minor preparatory work was necessary to get the data ready for our purposes here and is preserved in [this folder](https://github.com/njlyon0/collab_bilingualism/tree/main/dev) of the website's {{< fa brands github >}} GitHub repository.\n\n:::panel-tabset\n## [{{< fa brands r-project >}} R]{.r}\n\nThere are several [{{< fa brands r-project >}} R]{.r} packages for working with vector data but we'll focus on `sf`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load a shapefile of county borders\nvect_r <- sf::st_read(dsn = file.path(\"data\", \"nc.shp\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `nc' from data source \n  `/Users/nick.lyon/Documents/coding/collab_r-python-bilingualism/data/nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32377 ymin: 33.88212 xmax: -75.45662 ymax: 36.58973\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the class of this object\nclass(vect_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"sf\"         \"data.frame\"\n```\n\n\n:::\n:::\n\n\n## [{{< fa brands python >}} Python]{.py}\n\nThe `geopandas` library will be our focal library for vector operations with [{{< fa brands python >}} Python]{.py}.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Load a shapefile of county borders\nvect_py = gpd.read_file(os.path.join(\"data\", \"nc.shp\"))\n\n# Check the class of this object\ntype(vect_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<class 'geopandas.geodataframe.GeoDataFrame'>\n```\n\n\n:::\n:::\n\n:::\n\n## Vector Data Structure\n\nNote that vector data are often structurally similar to tabular data so some of the operations you can use in [Pandas]{.py}/[Tidyverse]{.r} [variables]{.py}/[objects]{.r} can be performed on these data. To demonstrate this, lets check the columns included in this vector data.\n\n:::panel-tabset\n## [{{< fa brands r-project >}} R]{.r}\n\nIn [{{< fa brands r-project >}} R]{.r} we can explore vector data using the `str` function. Note that the spatial information is stored in the \"geometry\" column; see the strange [class]{.r} attribute?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check columns\nstr(vect_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'sf' and 'data.frame':\t100 obs. of  15 variables:\n $ AREA     : num  0.114 0.061 0.143 0.07 0.153 0.097 0.062 0.091 0.118 0.124 ...\n $ PERIMETER: num  1.44 1.23 1.63 2.97 2.21 ...\n $ CNTY_    : num  1825 1827 1828 1831 1832 ...\n $ CNTY_ID  : num  1825 1827 1828 1831 1832 ...\n $ NAME     : chr  \"Ashe\" \"Alleghany\" \"Surry\" \"Currituck\" ...\n $ FIPS     : chr  \"37009\" \"37005\" \"37171\" \"37053\" ...\n $ FIPSNO   : num  37009 37005 37171 37053 37131 ...\n $ CRESS_ID : int  5 3 86 27 66 46 15 37 93 85 ...\n $ BIR74    : num  1091 487 3188 508 1421 ...\n $ SID74    : num  1 0 5 1 9 7 0 0 4 1 ...\n $ NWBIR74  : num  10 10 208 123 1066 ...\n $ BIR79    : num  1364 542 3616 830 1606 ...\n $ SID79    : num  0 3 6 2 3 5 2 2 2 5 ...\n $ NWBIR79  : num  19 12 260 145 1197 ...\n $ geometry :sfc_MULTIPOLYGON of length 100; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:27, 1:2] -81.5 -81.5 -81.6 -81.6 -81.7 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:14] \"AREA\" \"PERIMETER\" \"CNTY_\" \"CNTY_ID\" ...\n```\n\n\n:::\n:::\n\n\n## [{{< fa brands python >}} Python]{.py}\n\nIn [{{< fa brands python >}} Python]{.py} we can explore vector data via the `dtypes` attribute (which is also found in 'normal' tabular data variables). Note that the spatial information is stored in the \"geometry\" column; see the strange [type]{.py} attribute?\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Check columns\nvect_py.dtypes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAREA          float64\nPERIMETER     float64\nCNTY_         float64\nCNTY_ID       float64\nNAME           object\nFIPS           object\nFIPSNO        float64\nCRESS_ID        int32\nBIR74         float64\nSID74         float64\nNWBIR74       float64\nBIR79         float64\nSID79         float64\nNWBIR79       float64\ngeometry     geometry\ndtype: object\n```\n\n\n:::\n:::\n\n:::\n\n## Checking Vector CRS\n\nAs noted earlier, the very first thing we should do after reading in spatial data is _check the coordinate reference system!_\n\n:::panel-tabset\n## [{{< fa brands r-project >}} R]{.r}\n\nWe can check the CRS with the `st_crs` function (from `sf`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the CRS of the shapefile\nsf::st_crs(x = vect_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n```\n\n\n:::\n:::\n\n\n## [{{< fa brands python >}} Python]{.py}\n\n[{{< fa brands python >}} Python]{.py} stores vector CRS as an attribute.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Check the CRS of the shapefile\nvect_py.crs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Geographic 2D CRS: EPSG:4326>\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n```\n\n\n:::\n:::\n\n:::\n\n## Transforming Vector CRS\n\nOnce we know the current CRS, we can transform into a different coordinate reference system as needed. Let's transform from WGS84 into another commonly-used CRS: Albers Equal Area (EPSG code 3083).\n\nNote that while transforming a raster's CRS is very computationally intensive, transforming vector data CRS is _much_ faster. If you are trying to use vector and raster data together but they don't use the same CRS it can be quicker to transform the vector data to match the raster data (rather than vice versa).\n\n:::panel-tabset\n## [{{< fa brands r-project >}} R]{.r}\n\nFor CRS transformations in [{{< fa brands r-project >}} R]{.r} we can use the `st_transform` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Transform the shapefile CRS\nvect_alber_r <- sf::st_transform(x = vect_r, crs = 3083)\n\n# Re-check the CRS to confirm it worked\nsf::st_crs(vect_alber_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoordinate Reference System:\n  User input: EPSG:3083 \n  wkt:\nPROJCRS[\"NAD83 / Texas Centric Albers Equal Area\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"Texas Centric Albers Equal Area\",\n        METHOD[\"Albers Equal Area\",\n            ID[\"EPSG\",9822]],\n        PARAMETER[\"Latitude of false origin\",18,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8821]],\n        PARAMETER[\"Longitude of false origin\",-100,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8822]],\n        PARAMETER[\"Latitude of 1st standard parallel\",27.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8823]],\n        PARAMETER[\"Latitude of 2nd standard parallel\",35,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8824]],\n        PARAMETER[\"Easting at false origin\",1500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8826]],\n        PARAMETER[\"Northing at false origin\",6000000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8827]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"State-wide spatial data presentation requiring true area measurements.\"],\n        AREA[\"United States (USA) - Texas.\"],\n        BBOX[25.83,-106.66,36.5,-93.5]],\n    ID[\"EPSG\",3083]]\n```\n\n\n:::\n:::\n\n\n## [{{< fa brands python >}} Python]{.py}\n\n[{{< fa brands python >}} Python]{.py} CRS re-projections use the same process but the relevant method is `to_crs`.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Transform the shapefile CRS\nvect_alber_py = vect_py.to_crs(\"EPSG:3083\")\n\n# Re-check the CRS to confirm it worked\nvect_alber_py.crs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Projected CRS: EPSG:3083>\nName: NAD83 / Texas Centric Albers Equal Area\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: United States (USA) - Texas.\n- bounds: (-106.66, 25.83, -93.5, 36.5)\nCoordinate Operation:\n- name: Texas Centric Albers Equal Area\n- method: Albers Equal Area\nDatum: North American Datum 1983\n- Ellipsoid: GRS 1980\n- Prime Meridian: Greenwich\n```\n\n\n:::\n:::\n\n\n:::\n\n## Map Making with Vector Data\n\nOnce you've checked the CRS and confirmed it is appropriate, you may want to make a simple map. Again, because these data [variables]{.py}/[objects]{.r} have a similar structure to 'normal' tabular data we can use many of the same tools without modification.\n\n:::panel-tabset\n## [{{< fa brands r-project >}} R]{.r}\n\nThe base [{{< fa brands r-project >}} R]{.r} function `plot` works for spatial data too! Though note that it will make a separate map panel for each column in the data so we'll need to pick a particular column to get just one map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a map\nplot(vect_r[\"AREA\"])\n```\n\n::: {.cell-output-display}\n![](spatial_vector_files/figure-html/r-vect-map-1.png){width=672}\n:::\n:::\n\n\n## [{{< fa brands python >}} Python]{.py}\n\n[{{< fa brands python >}} Python]{.py} uses the `plot` method for this type of [variable]{.py}. Though note that without specifying the \"column\" argument we will get the map but every polygon will be filled with the default grey-blue color rather than informatively tied to another column in the data.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Make a map\nvect_py.plot(column = \"AREA\")\n```\n\n::: {.cell-output-display}\n![](spatial_vector_files/figure-html/py-vect-map-1.png){width=672}\n:::\n:::\n\n:::\n",
    "supporting": [
      "spatial_vector_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}