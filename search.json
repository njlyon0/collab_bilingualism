[
  {
    "objectID": "wrangle_reshape.html",
    "href": "wrangle_reshape.html",
    "title": "Reshaping Data",
    "section": "",
    "text": "Begin by loading any needed libraries and reading in an external data file for use in downstream examples.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package as well as our simulated lichen data.\n\n# Load needed library\nlibrary(tidyverse)\n\n# Load data\nlich_r &lt;- read.csv(file = file.path(\"data\", \"tree_lichen.csv\"))\n\n# Check out first few rows\nhead(lich_r, n = 3)\n\n    tree lichen_foliose lichen_fruticose lichen_crustose\n1 Tree_A           1.00              0.9            0.95\n2 Tree_B           0.35              1.0            0.00\n3 Tree_C           0.20              0.0            0.05\n\n\n\n\nLoad the Pandas and os libraries as well as our simulated lichen data.\n\n# Load needed libraries\nimport os\nimport pandas as pd\n\n# Load data\nlich_py = pd.read_csv(os.path.join(\"data\", \"tree_lichen.csv\"))\n\n# Check out first few rows\nlich_py.head(3)\n\n     tree  lichen_foliose  lichen_fruticose  lichen_crustose\n0  Tree_A            1.00               0.9             0.95\n1  Tree_B            0.35               1.0             0.00\n2  Tree_C            0.20               0.0             0.05"
  },
  {
    "objectID": "wrangle_reshape.html#library-data-loading",
    "href": "wrangle_reshape.html#library-data-loading",
    "title": "Reshaping Data",
    "section": "",
    "text": "Begin by loading any needed libraries and reading in an external data file for use in downstream examples.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package as well as our simulated lichen data.\n\n# Load needed library\nlibrary(tidyverse)\n\n# Load data\nlich_r &lt;- read.csv(file = file.path(\"data\", \"tree_lichen.csv\"))\n\n# Check out first few rows\nhead(lich_r, n = 3)\n\n    tree lichen_foliose lichen_fruticose lichen_crustose\n1 Tree_A           1.00              0.9            0.95\n2 Tree_B           0.35              1.0            0.00\n3 Tree_C           0.20              0.0            0.05\n\n\n\n\nLoad the Pandas and os libraries as well as our simulated lichen data.\n\n# Load needed libraries\nimport os\nimport pandas as pd\n\n# Load data\nlich_py = pd.read_csv(os.path.join(\"data\", \"tree_lichen.csv\"))\n\n# Check out first few rows\nlich_py.head(3)\n\n     tree  lichen_foliose  lichen_fruticose  lichen_crustose\n0  Tree_A            1.00               0.9             0.95\n1  Tree_B            0.35               1.0             0.00\n2  Tree_C            0.20               0.0             0.05"
  },
  {
    "objectID": "wrangle_reshape.html#understanding-data-shape",
    "href": "wrangle_reshape.html#understanding-data-shape",
    "title": "Reshaping Data",
    "section": "Understanding Data Shape",
    "text": "Understanding Data Shape\nAll tabular data can be said to have a “shape” that is either wide or long. This is often used to simply indicate whether there are more columns than there are rows but it is perhaps more accurate to say that wide data have variables in separate columns while long data usually has a column of variable names and a column of values. This distinction is important because you can have a data table with more rows than columns that is still in wide format (e.g., the simulated example lichen community data we just loaded).\nWhen wrangling data we may find it necessary to change the data from one shape to the other–this process is what is meant by “reshaping” (or sometimes “pivoting”). An example of each type of reshaping is included below."
  },
  {
    "objectID": "wrangle_reshape.html#reshaping-longer",
    "href": "wrangle_reshape.html#reshaping-longer",
    "title": "Reshaping Data",
    "section": "Reshaping Longer",
    "text": "Reshaping Longer\nOur lichen data are currently in wide format so let’s reshape into long format.\n\nR Project RPython Python\n\n\nR uses the pivot_longer function from the tidyr package for this operation. We need to specify the data table to reshape, the columns to collapse (to the cols argument), as well as the new column names for both the old column names and the values they contained. Fortunately the names_to and values_to arguments are reasonably intuitively named.\n\n# Reshape longer\nlong_r &lt;- tidyr::pivot_longer(data = lich_r,\n                              cols = c(lichen_foliose, lichen_fruticose, lichen_crustose),\n                              names_to = \"lichen_types\",\n                              values_to = \"percent_cover\")\n\n# Check out the first few rows of that\nhead(long_r, n = 3)\n\n# A tibble: 3 × 3\n  tree   lichen_types     percent_cover\n  &lt;chr&gt;  &lt;chr&gt;                    &lt;dbl&gt;\n1 Tree_A lichen_foliose            1   \n2 Tree_A lichen_fruticose          0.9 \n3 Tree_A lichen_crustose           0.95\n\n\nNote that the column names to reshape must be a vector.\n\n\nPython uses the melt function from the Pandas library for this operation. We need to specify the DataFrame to reshape, the columns to exclude from collapsing (with the id_vars argument), as well as the new column names for both the old column names and the values they contained. Fortunately the var_name and value_name arguments are reasonably intuitively named.\n\n# Reshape longer\nlong_py = pd.melt(frame = lich_py,\n                  id_vars = [\"tree\"],\n                  var_name = \"lichen_types\",\n                  value_name = \"percent_cover\")\n\n# Check out the first few rows of that\nlong_py.head(3)\n\n     tree    lichen_types  percent_cover\n0  Tree_A  lichen_foliose           1.00\n1  Tree_B  lichen_foliose           0.35\n2  Tree_C  lichen_foliose           0.20\n\n\nNote that the column names use as IDs must be a list (or similar object type)."
  },
  {
    "objectID": "wrangle_reshape.html#reshaping-wider",
    "href": "wrangle_reshape.html#reshaping-wider",
    "title": "Reshaping Data",
    "section": "Reshaping Wider",
    "text": "Reshaping Wider\nThe opposite operation–reshaping wider–is also readily available in either Python Python or R Project R. We’ll reshape the data we made into long format above to demonsrate re-reshaping back into wide format.\n\nR Project RPython Python\n\n\nR uses the pivot_wider function (also from the tidyr package) to do this type of reshaping operation. Reshaping wider requires fewer arguments as only the columns to reshape need to be specified.\n\n# Reshape (back) into wide format\nwide_r &lt;- tidyr::pivot_wider(data = long_r,\n                             names_from = \"lichen_types\",\n                             values_from = \"percent_cover\")\n\n# Check out the first few rows\nhead(wide_r, n = 2)\n\n# A tibble: 2 × 4\n  tree   lichen_foliose lichen_fruticose lichen_crustose\n  &lt;chr&gt;           &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;\n1 Tree_A           1                 0.9            0.95\n2 Tree_B           0.35              1              0   \n\n\n\n\nWe can use the Pandas function pivot_table to reshape back into wide format. Unlike R, we do need to specify the index column label(s) that are not being reshaped.\n\n# Reshape (back) into wide format\nwide_py = pd.pivot_table(data = long_py,\n                         index = [\"tree\"], \n                         columns = \"lichen_types\",\n                         values = \"percent_cover\")\n                         \n# Do some small index reformatting steps\nwide_py = wide_py.reset_index().rename_axis(mapper = None, axis = 1)\n\n# Check out the first few rows\nwide_py.head(2)\n\n     tree  lichen_crustose  lichen_foliose  lichen_fruticose\n0  Tree_A             0.95            1.00               0.9\n1  Tree_B             0.00            0.35               1.0\n\n\nThe reset index step is needed to get the index to look like it did before we melted it."
  },
  {
    "objectID": "workbench.html",
    "href": "workbench.html",
    "title": "Workbench",
    "section": "",
    "text": "Place to store snippets of code / formatting that I’ll be copy/pasting a bunch"
  },
  {
    "objectID": "workbench.html#template-tabset-panel-area",
    "href": "workbench.html#template-tabset-panel-area",
    "title": "Workbench",
    "section": "Template Tabset Panel Area",
    "text": "Template Tabset Panel Area\n\nR Project RPython Python\n\n\n\n# X\n\n\n\n\n# X\n\n\n\n\nvariables/objects\nPython Python or R Project R"
  },
  {
    "objectID": "wrangle_subset.html",
    "href": "wrangle_subset.html",
    "title": "Subsetting Data",
    "section": "",
    "text": "Begin by loading any needed libraries.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package.\n\nlibrary(tidyverse)\n\n\n\nLoad the Pandas and os libraries.\n\n# Load needed libraries\nimport os\nimport pandas as pd"
  },
  {
    "objectID": "wrangle_subset.html#library-loading",
    "href": "wrangle_subset.html#library-loading",
    "title": "Subsetting Data",
    "section": "",
    "text": "Begin by loading any needed libraries.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package.\n\nlibrary(tidyverse)\n\n\n\nLoad the Pandas and os libraries.\n\n# Load needed libraries\nimport os\nimport pandas as pd"
  },
  {
    "objectID": "wrangle_subset.html#conditionals",
    "href": "wrangle_subset.html#conditionals",
    "title": "Subsetting Data",
    "section": "Conditionals",
    "text": "Conditionals\nOften when we work with data we want to retrieve only the rows that meet some condition(s). These conditions can be defined in code by using “relational operators”. Fortunately, the fundamental relational operators are the same between Python Python and R Project R!\nConditional statements always return “boolean” [boo-lee-un] values. These are type boolean and class logical in Python Python and R Project R respectively.\n\nR Project RPython Python\n\n\nIn R TRUE and FALSE are booleans. Note that their abbreviations T and F are also accepted though they must be capitalized.\n\n# Assess whether a number equals itself and assign to an object\nbool_r &lt;- 20 == 20\n\n# See what that object contains\nbool_r\n\n[1] TRUE\n\n\n\n# And check class\nclass(bool_r)\n\n[1] \"logical\"\n\n\n\n\nIn Python True or False are booleans. Note that they must be capitalized in this way to register as the correct type (i.e., only first letter capitalized).\n\n# Assess whether a number equals itself and assign to an object\nbool_py = 20 == 20\n\n# See what that object contains\nbool_py\n\nTrue\n\n\n\n# Also check type\ntype(bool_py)\n\n&lt;class 'bool'&gt;\n\n\n\n\n\nIn addition to asking whether something ‘is exactly equal to’ something else (==), we can also ask whether two values are not equal (!=) or pose greater/less than conditionals (&gt;/&lt;).\n\nR Project RPython Python\n\n\n\n# Ask whether a number is less than or equal to a particular value\n7 &lt;= 5\n\n[1] FALSE\n\n\n\n\n\n# Ask whether a number is less than or equal to a particular value\n7 &lt;= 5\n\nFalse"
  },
  {
    "objectID": "wrangle_subset.html#subsetting-with-one-condition",
    "href": "wrangle_subset.html#subsetting-with-one-condition",
    "title": "Subsetting Data",
    "section": "Subsetting with One Condition",
    "text": "Subsetting with One Condition\nWe can leverage these conditional values to return only rows of a data table that meet criteria that are valuable to us. Let’s begin by loading the external dataset derived from the lterdatasampler R package (see here) that we used in the previous section.\n\nR Project RPython Python\n\n\nRead in vertebrate data CSV and check out the first few rows.\n\n# Load data\nvert_r &lt;- utils::read.csv(file = file.path(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nhead(vert_r, n = 3)\n\n  year sitecode section reach pass unitnum unittype vert_index pitnumber\n1 1987 MACKCC-L      CC     L    1       1        R          1        NA\n2 1987 MACKCC-L      CC     L    1       1        R          2        NA\n3 1987 MACKCC-L      CC     L    1       1        R          3        NA\n          species length_1_mm length_2_mm weight_g clip sampledate notes\n1 Cutthroat trout          58          NA     1.75 NONE 1987-10-07      \n2 Cutthroat trout          61          NA     1.95 NONE 1987-10-07      \n3 Cutthroat trout          89          NA     5.60 NONE 1987-10-07      \n\n\nRecall from our file path module that the file.path function accounts for computer operating system differences.\n\n\nRead in vertebrate data CSV (remember we must namespace the read_csv function) and check out the first few rows.\n\n# Load data\nvert_py = pd.read_csv(os.path.join(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nvert_py.head(3)\n\n   year  sitecode section reach  ...  weight_g  clip  sampledate  notes\n0  1987  MACKCC-L      CC     L  ...      1.75  NONE  1987-10-07    NaN\n1  1987  MACKCC-L      CC     L  ...      1.95  NONE  1987-10-07    NaN\n2  1987  MACKCC-L      CC     L  ...      5.60  NONE  1987-10-07    NaN\n\n[3 rows x 16 columns]\n\n\nRecall from our file path module that the join function accounts for computer operating system differences.\n\n\n\nNow that we have some data we can use conditional statements to actually subset it! We’ll use the len and nrow functions in Python Python and R Project R respectively to demonstrate that we successfully subset. Either will show whether we’ve successfully removed the rows that don’t meet our criteria.\n\nR Project RPython Python\n\n\nLet’s subset to only one particular site of vertebrate data. Note that ‘base R’ does include a subset function but we’ll use the equivalent filter function from the dplyr package.\n\n# Subset to only site \"MACKOG-U\"\nr_sub1 &lt;- dplyr::filter(vert_r, sitecode == \"MACKOG-U\")\n\n# Check whether that worked\nmessage(\"Before subsetting the data had \", nrow(vert_r), \" rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nmessage(\"Subsetting changed this to \", nrow(r_sub1))\n\nSubsetting changed this to 5726\n\n\n\n\nLet’s subset to only one particular site of vertebrate data.\n\n# Subset to only site \"MACKOG-U\"\npy_sub1 = vert_py[vert_py.sitecode == \"MACKOG-U\"]\n\n# Check whether that worked\nprint(\"Before subsetting the data had\", len(vert_py), \"rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nprint(\"Subsetting changed this to\", len(py_sub1))\n\nSubsetting changed this to 5726"
  },
  {
    "objectID": "wrangle_subset.html#subsetting-with-multiple-conditions",
    "href": "wrangle_subset.html#subsetting-with-multiple-conditions",
    "title": "Subsetting Data",
    "section": "Subsetting with Multiple Conditions",
    "text": "Subsetting with Multiple Conditions\nIf desired we can also specify multiple criteria to subset by. We must decide whether all criteria must be met or if any criterion being met is sufficient to retain the row. If we want all (in either language) we need to separate each criterion with an ampersand (&). If instead we want any (in either language) we need to separate each criterion with a pipe (|); note that this is not the same as a “pipe operator” which we’ll discuss in detail later.\n\nR Project RPython Python\n\n\nIf we want a only values between a minimum and maximum value that means we need all criteria to be met so we need to use a & between conditions.\n\n# Subset to only data from after 1990 before 1995 (inclusive)\nr_sub2 &lt;- dplyr::filter(vert_r, year &gt;= 1990 & year &lt;= 1995)\n\n# Check whether that worked\nmessage(\"Before subsetting the data had \", nrow(vert_r), \" rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nmessage(\"Subsetting changed this to \", nrow(r_sub2))\n\nSubsetting changed this to 4161\n\n\n\n\nIf we want a only values between a minimum and maximum value that means we need all criteria to be met so we need to use a & between conditions. Note that when we specify multiple criteria in Python we must wrap each conditional in parentheses.\n\n# Subset to only data from after 1990 before 1995 (inclusive)\npy_sub2 = vert_py[(vert_py.year &gt;= 1990) & (vert_py.year &lt;= 1995)]\n\n# Check whether that worked\nprint(\"Before subsetting the data had\", len(vert_py), \"rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nprint(\"Subsetting changed this to\", len(py_sub2))\n\nSubsetting changed this to 4161"
  },
  {
    "objectID": "wrangle_subset.html#subsetting-with-masks",
    "href": "wrangle_subset.html#subsetting-with-masks",
    "title": "Subsetting Data",
    "section": "Subsetting with Masks",
    "text": "Subsetting with Masks\nWe can define “boolean masks” when we want to leverage a helper function that tests for specific crtieria. For instance we can use the isin method or the %in% operator (in Python Python and R Project R respectively) to ask whether the value in a given row matches any of a set of options. This is much simpler than writing out one “or” criterion for every option individually.\n\nR Project RPython Python\n\n\nLet’s subset to only salamander species in the dataset using a mask. In R, that means providing the column name to the left of the %in% operator and giving a vector of options to the right.\n\n# Make the subset\nr_mask1 &lt;- dplyr::filter(vert_r, species %in% c(\"Coastal giant salamander\", \"Cascade torrent salamander\"))\n\n# Check whether that worked\nmessage(\"Before subsetting the data had \", nrow(vert_r), \" rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nmessage(\"Subsetting changed this to \", nrow(r_mask1))\n\nSubsetting changed this to 11773\n\n\n\n\nLet’s subset to only salamander species in the dataset using a mask. In Python, the isin method is a method so it is appended to the right of the column it accesses (separated by a period) and the options must be provided as a list (i.e., wrapped in square brackets and separated by commas).\n\n# Make the subset\npy_mask1 = vert_py[vert_py.species.isin([\"Coastal giant salamander\", \"Cascade torrent salamander\"])]\n\n# Check whether that worked\nprint(\"Before subsetting the data had\", len(vert_py), \"rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nprint(\"Subsetting changed this to\", len(py_mask1))\n\nSubsetting changed this to 11773"
  },
  {
    "objectID": "wrangle_subset.html#negating-criteria",
    "href": "wrangle_subset.html#negating-criteria",
    "title": "Subsetting Data",
    "section": "Negating Criteria",
    "text": "Negating Criteria\nSometimes it is helpful to negate criteria and subset to only conditions that don’t meet our criteria. This works with either simpler conditional statements or with masks! The symbol we use to do this negation differs between the two languages but in either it is placed to the left of the criterion it is negating.\nIn the below example we’ll use the isnull function or the is.na function to see whether a column contains missing values and invert it to return only rows where the specified column is not missing values.\n\nR Project RPython Python\n\n\nIn R we negate conditions by adding an exclamation point (!) to the left of the relevant criterion.\n\n# Subset to only species that *have* a recorded value in the \"length_2_mm\" column\nr_mask2 &lt;- dplyr::filter(vert_r, !is.na(length_2_mm))\n\n# Check whether that worked\nmessage(\"Before subsetting the data had \", nrow(vert_r), \" rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nmessage(\"Subsetting changed this to \", nrow(r_mask2))\n\nSubsetting changed this to 12560\n\n\n\n\nIn Python we negate conditions by adding a tilde (~) to the left of the relevant criterion.\n\n# Subset to only species that *have* a recorded value in the \"length_2_mm\" column\npy_mask2 = vert_py[~pd.isnull(vert_py.length_2_mm)]\n\n# Check whether that worked\nprint(\"Before subsetting the data had\", len(vert_py), \"rows.\")\n\nBefore subsetting the data had 32209 rows.\n\nprint(\"Subsetting changed this to\", len(py_mask2))\n\nSubsetting changed this to 12560"
  },
  {
    "objectID": "libs.html",
    "href": "libs.html",
    "title": "Packages & Libraries",
    "section": "",
    "text": "Packages must first be installed before they can be loaded. Installing a package is equivalent to going to a hardware store and buying a pre-made set of tools whereas loading that package is more like retrieving a set of tools that you already own and putting them in your work space so they are available to use. All sections of this website assume you have already installed the needed packages so consult the package installtion instructions on the home page of the site if you have not already done so.\nNote also that “package” and “library” are functionally interchangeable for our purposes though it is more common to say that packages are installed and libraries are loaded."
  },
  {
    "objectID": "libs.html#installation-versus-loading",
    "href": "libs.html#installation-versus-loading",
    "title": "Packages & Libraries",
    "section": "",
    "text": "Packages must first be installed before they can be loaded. Installing a package is equivalent to going to a hardware store and buying a pre-made set of tools whereas loading that package is more like retrieving a set of tools that you already own and putting them in your work space so they are available to use. All sections of this website assume you have already installed the needed packages so consult the package installtion instructions on the home page of the site if you have not already done so.\nNote also that “package” and “library” are functionally interchangeable for our purposes though it is more common to say that packages are installed and libraries are loaded."
  },
  {
    "objectID": "libs.html#library-loading",
    "href": "libs.html#library-loading",
    "title": "Packages & Libraries",
    "section": "Library Loading",
    "text": "Library Loading\nAssuming you’ve already installed the needed Python Python and R Project R packages, you can now load them.\n\nR Project RPython Python\n\n\nR libraries are loaded with the library function.\n\nlibrary(tidyverse)\n\n\n\nPython libraries are loaded with the import statement and can be “aliased” into simpler names with as at the same time. Note that common libraries (like Pandas) have broadly-accepted abbreviations that are almost always used (like pd in the case of Pandas).\n\nimport pandas as pd\n\n\n\n\nWith that, you’re all done loading libraries! Note however that you will need to re-load your libraries every time you quit and re-open your IDE (Integrated Developer Environment) such as Conda or RStudio. Restarting your session will also necessitate re-loading your libraries. That said, you only need to install packages once!"
  },
  {
    "objectID": "wrangle_join.html",
    "href": "wrangle_join.html",
    "title": "Joining Data",
    "section": "",
    "text": "Begin by loading any needed libraries.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package.\n\n# Load needed library\nlibrary(tidyverse)\n\n\n\nLoad the Pandas and os libraries.\n\n# Load needed libraries\nimport os\nimport pandas as pd"
  },
  {
    "objectID": "wrangle_join.html#library-loading",
    "href": "wrangle_join.html#library-loading",
    "title": "Joining Data",
    "section": "",
    "text": "Begin by loading any needed libraries.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package.\n\n# Load needed library\nlibrary(tidyverse)\n\n\n\nLoad the Pandas and os libraries.\n\n# Load needed libraries\nimport os\nimport pandas as pd"
  },
  {
    "objectID": "wrangle_join.html#combining-dataframes",
    "href": "wrangle_join.html#combining-dataframes",
    "title": "Joining Data",
    "section": "Combining DataFrames",
    "text": "Combining DataFrames\nSometimes we collected related data and store them in separate files. This necessitates integrating the two datasets later on for statistics and/or visualization. If the two datasets that are sampled at very different frequencies (e.g., annual temperature values and daily insect counts), trying to include both in a single file results in duplicating the less granular data many times. This is not ideal. Fortunately, scripted languages provide several methods for combining data easily and appropriately so that they can be used together despite being stored separately.\nTo illustrate some of these methods we’ll load some new simulated data on lichen coverage to use instead of the vertebrate data we’ve used in past modules.\n\nR Project RPython Python\n\n\nLoad the vertebrate data first.\n\n# Load data\nvert_r &lt;- read.csv(file = file.path(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nhead(vert_r, n = 2)\n\n  year sitecode section reach pass unitnum unittype vert_index pitnumber\n1 1987 MACKCC-L      CC     L    1       1        R          1        NA\n2 1987 MACKCC-L      CC     L    1       1        R          2        NA\n          species length_1_mm length_2_mm weight_g clip sampledate notes\n1 Cutthroat trout          58          NA     1.75 NONE 1987-10-07      \n2 Cutthroat trout          61          NA     1.95 NONE 1987-10-07      \n\n\nThen load the dataset with lichen community composition on trees.\n\n# Load data\nlich &lt;- read.csv(file = file.path(\"data\", \"tree_lichen.csv\"))\n\n# Check out rows rows\nhead(lich, n = 2)\n\n    tree lichen_foliose lichen_fruticose lichen_crustose\n1 Tree_A           1.00              0.9            0.95\n2 Tree_B           0.35              1.0            0.00\n\n\nAnd finally load the data that includes distance from the nearest road for some of the same trees for which we have lichen data.\n\n# Load data\nroad &lt;- read.csv(file = file.path(\"data\", \"tree_road.csv\"))\n\n# Check out rows\nhead(road, n = 2)\n\n  tree_name dist_to_road_m\n1    Tree_A             13\n2    Tree_C             10\n\n\n\n\nLoad the vertebrate data first.\n\n# Load data\nvert_py = pd.read_csv(os.path.join(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nvert_py.head(2)\n\n   year  sitecode section reach  ...  weight_g  clip  sampledate  notes\n0  1987  MACKCC-L      CC     L  ...      1.75  NONE  1987-10-07    NaN\n1  1987  MACKCC-L      CC     L  ...      1.95  NONE  1987-10-07    NaN\n\n[2 rows x 16 columns]\n\n\nThen load the dataset with lichen community composition on trees.\n\n# Load data\nlich = pd.read_csv(os.path.join(\"data\", \"tree_lichen.csv\"))\n\n# Check out rows\nlich.head(2)\n\n     tree  lichen_foliose  lichen_fruticose  lichen_crustose\n0  Tree_A            1.00               0.9             0.95\n1  Tree_B            0.35               1.0             0.00\n\n\nAnd finally load the data that includes distance from the nearest road for some of the same trees for which we have lichen data.\n\n# Load data\nroad = pd.read_csv(os.path.join(\"data\", \"tree_road.csv\"))\n\n# Check out rows\nroad.head(2)\n\n  tree_name  dist_to_road_m\n0    Tree_A              13\n1    Tree_C              10"
  },
  {
    "objectID": "wrangle_join.html#concatenating-data",
    "href": "wrangle_join.html#concatenating-data",
    "title": "Joining Data",
    "section": "Concatenating Data",
    "text": "Concatenating Data\nThe simplest way of combining data in either Python Python or R Project R is called “concatenation”. This involves–essentially–pasting rows or columns of separate data variables/objects together.\nWe’ll need to modify our vertebrate data somewhat in order to demonstrate the two modes (horizontal or vertical) of concatenating DataFrames/data.frames.\nConcatenating data (either horizontally or vertically) in this way is deeply risky in that it can easily result in creating rows or columns that appear to relate to one another but in actuality do not. However, it is still worthwhile to cover how this can be done.\n\nR Project RPython Python\n\n\nSplit the first and last two rows of the vertebrate data into separate objects. Note that in each we’ll want to retain all columns.\n\n# Split the two datasets\nvert_r_top &lt;- vert_r[1:2, ]\nvert_r_bottom &lt;- vert_r[(nrow(vert_r) - 1):nrow(vert_r), ]\n\n# Look at one\nvert_r_bottom\n\n      year sitecode section reach pass unitnum unittype vert_index pitnumber\n32208 2019 MACKOG-U      OG     U    2      16        C         25   1043583\n32209 2019 MACKOG-U      OG     U    2      16        C         26   1043500\n                       species length_1_mm length_2_mm weight_g clip sampledate\n32208 Coastal giant salamander          74         131     14.3 NONE 2019-09-05\n32209 Coastal giant salamander          73         128     11.6 NONE 2019-09-05\n            notes\n32208            \n32209 Terrestrial\n\n\n\n\nSplit the first and last two rows of the vertebrate data into separate variables. Note that in each we’ll want to retain all columns.\n\n# Split the two datasets\nvert_py_top = vert_py.iloc[[0, 1], :]\nvert_py_bottom = vert_py.iloc[[-1, -2], :]\n\n# Look at one\nvert_py_bottom\n\n       year  sitecode section reach  ...  weight_g  clip  sampledate        notes\n32208  2019  MACKOG-U      OG     U  ...      11.6  NONE  2019-09-05  Terrestrial\n32207  2019  MACKOG-U      OG     U  ...      14.3  NONE  2019-09-05          NaN\n\n[2 rows x 16 columns]\n\n\n\n\n\n\nVertical Concatenation\nVertical concatenation (i.e., concatenating by stacking rows on top of each other) is one option for concatenation. This is much more common than horizontal concatenation.\n\nR Project RPython Python\n\n\nR can perform this operation with the rbind function (from base R) but the bind_rows function (from the dplyr package) is preferable because it checks for matching column names and–if necessary–reorders columns to match between the two data objects.\n\n# Combine vertically\nvert_r_vertical &lt;- dplyr::bind_rows(vert_r_top, vert_r_bottom)\n\n# Check shape before and after to demonstrate it worked\nmessage(\"There were two rows each before concatenation and \", nrow(vert_r_vertical), \" after\")\n\nThere were two rows each before concatenation and 4 after\n\n\n\n\nPython does horizontal concatenation with the concat function from the Pandas library. This function does horizontal and vertical concatenation and uses the axis argument to determine which is done. Setting axis to 0 performs vertical concatenation.\n\n# Combine vertically\nvert_py_vertical = pd.concat([vert_py_top, vert_py_bottom], axis = 0)\n\n# Check shape before and after to demonstrate it worked\nprint(\"There were two rows each before concatenation and\", len(vert_py_vertical), \"after\")\n\nThere were two rows each before concatenation and 4 after\n\n\n\n\n\n\n\nHorizontal Concatenation\nHorizontal concatenation (i.e., concatenating by putting columns next to one another) is the other option for concatenation. Note that it assumes row orders are consistent and won’t perform any check for improper row combinations. Also, both languages will create duplicate column labels/names in our example because both data variables/objects have the same column labels/names.\n\nR Project RPython Python\n\n\nR does horizontal concatenation with the cbind function from base R.\n\n# Combine horizontally\nvert_r_horiz &lt;- cbind(vert_r_top, vert_r_bottom)\n\n# Check columns to show they were added\nnames(vert_r_horiz)\n\n [1] \"year\"        \"sitecode\"    \"section\"     \"reach\"       \"pass\"       \n [6] \"unitnum\"     \"unittype\"    \"vert_index\"  \"pitnumber\"   \"species\"    \n[11] \"length_1_mm\" \"length_2_mm\" \"weight_g\"    \"clip\"        \"sampledate\" \n[16] \"notes\"       \"year\"        \"sitecode\"    \"section\"     \"reach\"      \n[21] \"pass\"        \"unitnum\"     \"unittype\"    \"vert_index\"  \"pitnumber\"  \n[26] \"species\"     \"length_1_mm\" \"length_2_mm\" \"weight_g\"    \"clip\"       \n[31] \"sampledate\"  \"notes\"      \n\n\n\n\nSetting the axis argument to 1 is how the concat function is switched to horizontal concatenation.\n\n# Combine horizontally\nvert_py_horiz = pd.concat([vert_py_top, vert_py_bottom], axis = 1)\n\n# Check columns to show they were added\nvert_py_horiz.columns\n\nIndex(['year', 'sitecode', 'section', 'reach', 'pass', 'unitnum', 'unittype',\n       'vert_index', 'pitnumber', 'species', 'length_1_mm', 'length_2_mm',\n       'weight_g', 'clip', 'sampledate', 'notes', 'year', 'sitecode',\n       'section', 'reach', 'pass', 'unitnum', 'unittype', 'vert_index',\n       'pitnumber', 'species', 'length_1_mm', 'length_2_mm', 'weight_g',\n       'clip', 'sampledate', 'notes'],\n      dtype='object')"
  },
  {
    "objectID": "wrangle_join.html#joins",
    "href": "wrangle_join.html#joins",
    "title": "Joining Data",
    "section": "Joins",
    "text": "Joins\nWhile concatentation is simple and effective in some cases, a less risky mode of combining separate data objects is to use “joins”. Joins allow two data variables/objects to be combined in an appropriate order based on a column found in both data variables/objects. This shared column (or column_s_) are known as “join keys”.\nThis module makes use of simulated data on lichen coverage on various trees and the distance of those trees to the nearest road. Lichen wasn’t surveyed on all of the trees and not all trees that did have lichen measured had their distance to the nearest road recorded. Vertical concatenation is inappropriate because the column labels/names and horizontal concatenation is incorrect because we want to make sure we only combine data from the same tree across the two datasets.\nThere are several variants of joins that each function slightly differently so we’ll discuss each below. Note that all joins only combine two data variables/objects at a time and they are always referred to as the “left” (first) and “right” (second).\n\nLeft / Right Joins\nLeft joins combine two data variables/objects by their join key(s) but only keep rows that are found in the “left”. A right join performs the same operation but prioritizes rows in the second data variable/object. Note that functionally you can make a left join into a right join by switching which data variable/object you assign to “left” versus “right”.\n\n\n\n\nR Project RPython Python\n\n\nThe left_join function (from the dplyr package) performs–as its name suggests–left joins. The right_join function does the same for right joins. Both have an x and a y argument for the left and right data objects respectively.\nThe by argument expects a vector of join keys to by which to join. Note that if the join key column names differ–as is the case with our example data–you can specify that by using the syntax \"left key\" = \"right key\".\n\n# Do a left join\nleft_r &lt;- dplyr::left_join(x = lich, y = road, by = c(\"tree\" = \"tree_name\"))\n\n# Check that out\nhead(left_r, n = 5)\n\n    tree lichen_foliose lichen_fruticose lichen_crustose dist_to_road_m\n1 Tree_A           1.00              0.9            0.95             13\n2 Tree_B           0.35              1.0            0.00             NA\n3 Tree_C           0.20              0.0            0.05             10\n4 Tree_D           0.55              0.9            0.85             23\n5 Tree_E           0.85              0.9            0.25             20\n\n\nSee how “tree_B” has no distance to road listed? That is because it lacks a row in the right data object!\n\n\nAll Python joins are performed with the merge function (from the Pandas library) and the type of join is specified by the how argument. Which data variable is left and right is specified by arguments of the same name.\nThe on argument can be used when the join key(s) labels match but otherwise a left_on and right_on argument are provided to specify the join key’s label in the left and right data variable respectively.\n\n# Do a left join\nleft_py = pd.merge(left = lich, right = road, how = \"left\", \n                   left_on = \"tree\", right_on = \"tree_name\")\n\n# Check that out\nleft_py.head(5)\n\n     tree  lichen_foliose  ...  tree_name  dist_to_road_m\n0  Tree_A            1.00  ...     Tree_A            13.0\n1  Tree_B            0.35  ...        NaN             NaN\n2  Tree_C            0.20  ...     Tree_C            10.0\n3  Tree_D            0.55  ...     Tree_D            23.0\n4  Tree_E            0.85  ...     Tree_E            20.0\n\n[5 rows x 6 columns]\n\n\nSee how “tree_B” has no distance to road listed? That is because it lacks a row in the right data variable!\n\n\n\n\n\nInner Joins\n\n\n\nAn inner join keeps only the rows that can be found in both join keys. This is very useful in situations where only “complete” data (i.e., no missing values) is required.\n\nR Project RPython Python\n\n\nIn R, we can do an inner join with dplyr’s inner_join function. It has the same arguments as the left_join function.\n\n# Inner join the two datasets\nin_r &lt;- dplyr::inner_join(x = lich, y = road, by = c(\"tree\" = \"tree_name\"))\n\n# Check that out\nhead(in_r, n = 5)\n\n    tree lichen_foliose lichen_fruticose lichen_crustose dist_to_road_m\n1 Tree_A           1.00             0.90            0.95             13\n2 Tree_C           0.20             0.00            0.05             10\n3 Tree_D           0.55             0.90            0.85             23\n4 Tree_E           0.85             0.90            0.25             20\n5 Tree_L           0.75             0.35            1.00             17\n\n\n\n\nIn Python, an inner join is actually the default behavior of the merge function. Therefore we can exclude the how argument entirely!\n\n# Inner join the two datasets\nin_py = pd.merge(left = lich, right = road,\n                 left_on = \"tree\", right_on = \"tree_name\")\n\n# Check that out\nin_py.head(5)\n\n     tree  lichen_foliose  ...  tree_name  dist_to_road_m\n0  Tree_A            1.00  ...     Tree_A              13\n1  Tree_C            0.20  ...     Tree_C              10\n2  Tree_D            0.55  ...     Tree_D              23\n3  Tree_E            0.85  ...     Tree_E              20\n4  Tree_L            0.75  ...     Tree_L              17\n\n[5 rows x 6 columns]\n\n\n\n\n\n\n\nFull Joins\nA full join (sometimes known as an “outer join” or a “full outer join”) combines all rows in both left and right data variables/objects regardless of whether the join key entries are found in both.\n\n\n\n\nR Project RPython Python\n\n\nR uses the full_join function (from dplyr) and the same arguments as the other types of join that we’ve already discussed.\n\n# Do a full join\nfull_r &lt;- dplyr::full_join(x = lich, y = road, by = c(\"tree\" = \"tree_name\"))\n\n# Check that out\nhead(full_r, n = 5)\n\n    tree lichen_foliose lichen_fruticose lichen_crustose dist_to_road_m\n1 Tree_A           1.00              0.9            0.95             13\n2 Tree_B           0.35              1.0            0.00             NA\n3 Tree_C           0.20              0.0            0.05             10\n4 Tree_D           0.55              0.9            0.85             23\n5 Tree_E           0.85              0.9            0.25             20\n\n\n\n\nPython refers to full joins as “outer” joins so the how argument of the merge function needs to be set to “outer”.\n\n# Do a full join\nfull_py = pd.merge(left = lich, right = road, how = \"outer\",\n                   left_on = \"tree\", right_on = \"tree_name\")\n\n# Check that out\nfull_py.head(5)\n\n     tree  lichen_foliose  ...  tree_name  dist_to_road_m\n0  Tree_A            1.00  ...     Tree_A            13.0\n1  Tree_B            0.35  ...        NaN             NaN\n2  Tree_C            0.20  ...     Tree_C            10.0\n3  Tree_D            0.55  ...     Tree_D            23.0\n4  Tree_E            0.85  ...     Tree_E            20.0\n\n[5 rows x 6 columns]"
  },
  {
    "objectID": "wrangle_summarize.html",
    "href": "wrangle_summarize.html",
    "title": "Summarizing Data",
    "section": "",
    "text": "Begin by loading any needed libraries and reading in an external data file for use in downstream examples.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package as well as our vertebrate data.\n\n# Load needed library\nlibrary(tidyverse)\n\n# Load data\nvert_r &lt;- utils::read.csv(file = file.path(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nhead(vert_r, n = 5)\n\n  year sitecode section reach pass unitnum unittype vert_index pitnumber\n1 1987 MACKCC-L      CC     L    1       1        R          1        NA\n2 1987 MACKCC-L      CC     L    1       1        R          2        NA\n3 1987 MACKCC-L      CC     L    1       1        R          3        NA\n4 1987 MACKCC-L      CC     L    1       1        R          4        NA\n5 1987 MACKCC-L      CC     L    1       1        R          5        NA\n          species length_1_mm length_2_mm weight_g clip sampledate notes\n1 Cutthroat trout          58          NA     1.75 NONE 1987-10-07      \n2 Cutthroat trout          61          NA     1.95 NONE 1987-10-07      \n3 Cutthroat trout          89          NA     5.60 NONE 1987-10-07      \n4 Cutthroat trout          58          NA     2.15 NONE 1987-10-07      \n5 Cutthroat trout          93          NA     6.90 NONE 1987-10-07      \n\n\n\n\nLoad the Pandas and os libraries as well as our simulated lichen data.\n\n# Load needed libraries\nimport os\nimport pandas as pd\n\n# Load data\nvert_py = pd.read_csv(os.path.join(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nvert_py.head()\n\n   year  sitecode section reach  ...  weight_g  clip  sampledate  notes\n0  1987  MACKCC-L      CC     L  ...      1.75  NONE  1987-10-07    NaN\n1  1987  MACKCC-L      CC     L  ...      1.95  NONE  1987-10-07    NaN\n2  1987  MACKCC-L      CC     L  ...      5.60  NONE  1987-10-07    NaN\n3  1987  MACKCC-L      CC     L  ...      2.15  NONE  1987-10-07    NaN\n4  1987  MACKCC-L      CC     L  ...      6.90  NONE  1987-10-07    NaN\n\n[5 rows x 16 columns]"
  },
  {
    "objectID": "wrangle_summarize.html#library-data-loading",
    "href": "wrangle_summarize.html#library-data-loading",
    "title": "Summarizing Data",
    "section": "",
    "text": "Begin by loading any needed libraries and reading in an external data file for use in downstream examples.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package as well as our vertebrate data.\n\n# Load needed library\nlibrary(tidyverse)\n\n# Load data\nvert_r &lt;- utils::read.csv(file = file.path(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nhead(vert_r, n = 5)\n\n  year sitecode section reach pass unitnum unittype vert_index pitnumber\n1 1987 MACKCC-L      CC     L    1       1        R          1        NA\n2 1987 MACKCC-L      CC     L    1       1        R          2        NA\n3 1987 MACKCC-L      CC     L    1       1        R          3        NA\n4 1987 MACKCC-L      CC     L    1       1        R          4        NA\n5 1987 MACKCC-L      CC     L    1       1        R          5        NA\n          species length_1_mm length_2_mm weight_g clip sampledate notes\n1 Cutthroat trout          58          NA     1.75 NONE 1987-10-07      \n2 Cutthroat trout          61          NA     1.95 NONE 1987-10-07      \n3 Cutthroat trout          89          NA     5.60 NONE 1987-10-07      \n4 Cutthroat trout          58          NA     2.15 NONE 1987-10-07      \n5 Cutthroat trout          93          NA     6.90 NONE 1987-10-07      \n\n\n\n\nLoad the Pandas and os libraries as well as our simulated lichen data.\n\n# Load needed libraries\nimport os\nimport pandas as pd\n\n# Load data\nvert_py = pd.read_csv(os.path.join(\"data\", \"verts.csv\"))\n\n# Check out first few rows\nvert_py.head()\n\n   year  sitecode section reach  ...  weight_g  clip  sampledate  notes\n0  1987  MACKCC-L      CC     L  ...      1.75  NONE  1987-10-07    NaN\n1  1987  MACKCC-L      CC     L  ...      1.95  NONE  1987-10-07    NaN\n2  1987  MACKCC-L      CC     L  ...      5.60  NONE  1987-10-07    NaN\n3  1987  MACKCC-L      CC     L  ...      2.15  NONE  1987-10-07    NaN\n4  1987  MACKCC-L      CC     L  ...      6.90  NONE  1987-10-07    NaN\n\n[5 rows x 16 columns]"
  },
  {
    "objectID": "wrangle_summarize.html#defining-groups",
    "href": "wrangle_summarize.html#defining-groups",
    "title": "Summarizing Data",
    "section": "Defining Groups",
    "text": "Defining Groups\nNow that we have data, we can use it to demonstrate groupwise summarization! Both Python and R support defining the grouping structure in one step and then doing the actual summarization in subsequent steps.\nLet’s suppose that we want to calculate average weight and length within each species and year.\n\nR Project RPython Python\n\n\nIn R, we use the group_by function (from dplyr) to define our grouping variables. Note that this changes the class from data.frame to tibble (a special dataframe-like class defined by the tidyverse in part due to this operation).\ngroup_by–like other functions in the tidyverse–allows for ‘tidy select’ column names where column names are provided without quotes.\n\n# Define grouping variables\nvert_r_grp &lt;- dplyr::group_by(.data = vert_r, year, species)\n\n# Check class of resulting object\nclass(vert_r_grp)\n\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nIn Python, we can use the groupby method (available to all variables of type DataFrame). This method does accept multiple column labels but they must be provided as a list (i.e., wrapped in square brackets) and the labels themselves must be wrapped in quotes.\n\n# Define grouping variables\nvert_py_grp = vert_py.groupby([\"year\", \"species\"])\n\n# Check type of resulting variable\ntype(vert_py_grp)\n\n&lt;class 'pandas.core.groupby.generic.DataFrameGroupBy'&gt;"
  },
  {
    "objectID": "wrangle_summarize.html#groupwise-summarization",
    "href": "wrangle_summarize.html#groupwise-summarization",
    "title": "Summarizing Data",
    "section": "Groupwise Summarization",
    "text": "Groupwise Summarization\nOnce we’ve established the columns for which we want to calculate summary statistics we can move on to the tools that actually allow summarization steps to take place. Note that summarization implicitly means that we should lose rows because we should only have one row per combination of grouping column content combination. Adding columns is not necessarily summarization if it doesn’t shed rows.\n\nR Project RPython Python\n\n\nR allows for multiple summary metrics to be calculate simultaneously within dplyr’s summarize function.\n\n# Calculate average weight and length\nvert_r_summary &lt;- dplyr::summarize(.data = vert_r_grp,\n                 weight_g = mean(weight_g, na.rm = T),\n                 length_1_mm = mean(length_1_mm, na.rm = T),\n                 length_2_mm = mean(length_2_mm, na.rm = T))\n\n# Check out the first bit of that\nhead(vert_r_summary, n = 3)\n\n# A tibble: 3 × 5\n# Groups:   year [3]\n   year species         weight_g length_1_mm length_2_mm\n  &lt;int&gt; &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1  1987 Cutthroat trout     8.96        90.2         NaN\n2  1988 Cutthroat trout    16.1        115.          NaN\n3  1989 Cutthroat trout    14.3        107.          NaN\n\n\n\n\nWhen summarizing data in Python we need to calculate each metric separately and then combine them. Apologies that this uses the concat function in Pandas that we have not previously covered but you can see a greater discussion of these functions/methods in the “Join” section.\nNote the use of two modes of indexing a particular column.\n\n# Calculate average weight and length\nmean_wt = vert_py_grp[\"weight_g\"].mean()\nmean_ln1 = vert_py_grp.length_1_mm.mean()\nmean_ln2 = vert_py_grp[\"length_2_mm\"].mean()\n\n# Combine them\nvert_py_summary = pd.concat([mean_wt, mean_ln1, mean_ln2], axis = 1)\n\n# Do some small index reformatting steps\nvert_py_summary = vert_py_summary.reset_index().rename_axis(mapper = None, axis = 1)\n\n# Check out that\nvert_py_summary.head(3)\n\n   year          species   weight_g  length_1_mm  length_2_mm\n0  1987  Cutthroat trout   8.959867    90.170813          NaN\n1  1988  Cutthroat trout  16.073510   115.417219          NaN\n2  1989  Cutthroat trout  14.308766   107.038961          NaN\n\n\nThe index re-setting is needed for Python just to make sure the columns and rows are indexed as they should be."
  },
  {
    "objectID": "sql.html",
    "href": "sql.html",
    "title": "SQL",
    "section": "",
    "text": "So far, we’ve been able to use Python Python or R Project R on CSV files without issue. However, when the data that we are working with become very large (e.g., millions of rows) it can be very inefficient to rely on your computer’s internal memory to do operations. Database SQL (Structured Query Language) is another programming language specifically built to work with larger databases where users “query” just the component of the data that they need for a given operation. This minimizes the amount of data that must be held in memory at any given time.\nA caveat before we begin: Database SQL is a fully fledged language in its own right that carries a suite of verbs and syntax conventions. We’ll need to engage with these a little in our examples but this website is not meant as a tutorial in this language. Note that R Project R users may have some SQL intuition already because SQL shares many of its verbs with the dplyr package."
  },
  {
    "objectID": "sql.html#overview",
    "href": "sql.html#overview",
    "title": "SQL",
    "section": "",
    "text": "So far, we’ve been able to use Python Python or R Project R on CSV files without issue. However, when the data that we are working with become very large (e.g., millions of rows) it can be very inefficient to rely on your computer’s internal memory to do operations. Database SQL (Structured Query Language) is another programming language specifically built to work with larger databases where users “query” just the component of the data that they need for a given operation. This minimizes the amount of data that must be held in memory at any given time.\nA caveat before we begin: Database SQL is a fully fledged language in its own right that carries a suite of verbs and syntax conventions. We’ll need to engage with these a little in our examples but this website is not meant as a tutorial in this language. Note that R Project R users may have some SQL intuition already because SQL shares many of its verbs with the dplyr package."
  },
  {
    "objectID": "sql.html#library-loading",
    "href": "sql.html#library-loading",
    "title": "SQL",
    "section": "Library Loading",
    "text": "Library Loading\nBegin by loading the needed libraries.\n\nR Project RPython Python\n\n\nLoad the DBI package.\n\n# Load needed libraries\nlibrary(DBI)\n\n\n\nLoad the Pandas, os, and sqlite3 packages.\n\n# Load needed libraries\nimport os\nimport pandas as pd\nimport sqlite3"
  },
  {
    "objectID": "sql.html#connecting-to-databases",
    "href": "sql.html#connecting-to-databases",
    "title": "SQL",
    "section": "Connecting to Databases",
    "text": "Connecting to Databases\nSQLite operations require us to connect to a database, perform desired operations, and then close the connection when we are finished. A good introduction to this is showing how one can list the data tables available in a given database; this is vital information for doing any “real” queries as we need to know the name of the table from which we want to extract data.\n\nR Project RPython Python\n\n\nIn R we can open the connection with the dbConnect function, identify the tables in the database with the dbListTables function and–eventually–close the connection with the dbDisconnect function (all of which are in the DBI package).\n\n# Open the connection\ncxn &lt;- DBI::dbConnect(RSQLite::SQLite(), file.path(\"data\", \"mammals.sqlite\"))\n\n# Identify tables in the database\nDBI::dbListTables(conn = cxn)\n\n[1] \"plots\"   \"species\" \"surveys\"\n\n# Close the connection\nDBI::dbDisconnect(conn = cxn)\n\n\n\nIn Python we can open the connection with the connect function (from the sqlite3 library), identify the tables in the database with the read_sql_query function (from pandas) and–eventually–close the connection with the close method.\n\n# Open the connection\ncxn = sqlite3.connect(os.path.join(\"data\", \"mammals.sqlite\"))\n\n# Query some columns in the 'surveys' object\npd.read_sql_query(sql = \"SELECT name FROM sqlite_master WHERE type = 'table'\", con = cxn)\n\n      name\n0  surveys\n1  species\n2    plots\n\n\n# Close the connection\ncxn.close()"
  },
  {
    "objectID": "sql.html#extracting-data",
    "href": "sql.html#extracting-data",
    "title": "SQL",
    "section": "Extracting Data",
    "text": "Extracting Data\nConnecting and listing the available data in a given database is all well and good but really what we want to do is extract some of the data for later use. To do this we still need to open (and eventually close!) the connection but between those two steps we can use Database SQL syntax to actually perform a query. Note that it is a good practice to fully capitalize Database SQL verbs (e.g., SELECT) to help differentiate them from column / data table names.\nAt a minimum a query must involve SELECT to dictate which columns to keep (accepts either column names or a * for ‘all columns’) and FROM to indicate which table in the database we want to query.\n\nR Project RPython Python\n\n\n\n# Open the connection\ncxn &lt;- DBI::dbConnect(RSQLite::SQLite(), file.path(\"data\", \"mammals.sqlite\"))\n\n# Query some columns in the 'surveys' object\nquery_r &lt;- DBI::dbGetQuery(conn = cxn, statement = \"SELECT year, species_id, plot_id FROM surveys\")\n\n# Close the connection\nDBI::dbDisconnect(conn = cxn)\n\nNote that we can still use the query data object even when we have closed our database connection!\n\n# Check out the first few rows of that\nhead(query_r, n = 4)\n\n  year species_id plot_id\n1 1977         NL       2\n2 1977         NL       3\n3 1977         DM       2\n4 1977         DM       7\n\n\n\n\n\n# Open the connection\ncxn = sqlite3.connect(os.path.join(\"data\", \"mammals.sqlite\"))\n\n# Query some columns in the 'surveys' object\nquery_py = pd.read_sql_query(sql = \"SELECT year, species_id, plot_id FROM surveys\", con = cxn)\n\n# Close the connection\ncxn.close()\n\nNote that we can still use the query data object even when we have closed our database connection!\n\n# Check out the first few rows of that\nquery_py.head(4)\n\n   year species_id  plot_id\n0  1977         NL        2\n1  1977         NL        3\n2  1977         DM        2\n3  1977         DM        7"
  },
  {
    "objectID": "string_methods.html",
    "href": "string_methods.html",
    "title": "Text Methods",
    "section": "",
    "text": "Data stored as text (i.e., string/object or character) is notoriously typo-prone and often requires extensive quality control checks throughout the data tidying process. Below is a–non exhaustive–set of common text methods that may prove valuable to people interested in dealing with text data in either Python Python or R Project R."
  },
  {
    "objectID": "string_methods.html#overview",
    "href": "string_methods.html#overview",
    "title": "Text Methods",
    "section": "",
    "text": "Data stored as text (i.e., string/object or character) is notoriously typo-prone and often requires extensive quality control checks throughout the data tidying process. Below is a–non exhaustive–set of common text methods that may prove valuable to people interested in dealing with text data in either Python Python or R Project R."
  },
  {
    "objectID": "string_methods.html#find-replace",
    "href": "string_methods.html#find-replace",
    "title": "Text Methods",
    "section": "Find & Replace",
    "text": "Find & Replace\nThe bulk of text tidying often boils down to finding unwanted strings/characters and replacing them with desired variants. This operation is how computers handle fixing typos.\n\nR Project RPython Python\n\n\nWe can use the base R function gsub to find and replace (part of) a character object.\n\n# Make a vector of characters\ntext_r &lt;- c(\"he1lo\", \"HELLO\", \"bye\")\n\n# Find and replace the number \"1\" with an \"L\"\nfix1_r &lt;- gsub(pattern = \"1\", replacement = \"l\", x = text_r)\n\n# Print the result\nprint(fix1_r)\n\n[1] \"hello\" \"HELLO\" \"bye\"  \n\n\n\n\nWe can use the Python method replace to find and replace (part of) a string/object variable.\n\n# Make a list of strings\ntext_py = [\"he1lo\", \"HELLO\", \"bye\"]\n\n# Find and replace the number \"1\" with an \"L\"\nfix1_py = [item.replace(\"1\", \"l\") for item in text_py]\n\n# Print the result\nprint(fix1_py)\n\n['hello', 'HELLO', 'bye']\n\n\nNote that we have to loop across our list to do this operation in this language."
  },
  {
    "objectID": "string_methods.html#casing",
    "href": "string_methods.html#casing",
    "title": "Text Methods",
    "section": "Casing",
    "text": "Casing\nText casing (i.e., either UPPERCASE or lowercase) is also a frequent source of issues in code as many scripted operations are sensitive to text case. We can coerce to upper or lowercase as needed though with relative ease.\n\nR Project RPython Python\n\n\nWe can use the tolower or toupper functions (also from base R) to coerce all text into lower or uppercase respectively.\n\n# Coerce everything to lowercase\nfix2_r &lt;- tolower(x = fix1_r)\n\n# Print the result\nprint(fix2_r)\n\n[1] \"hello\" \"hello\" \"bye\"  \n\n\n\n\nWe can use the lower or upper methods to coerce all text into lower or uppercase respectively.\n\n# Coerce everything to lowercase\nfix2_py = [item.lower() for item in fix1_py]\n\n# Print the result\nprint(fix2_py)\n\n['hello', 'hello', 'bye']"
  },
  {
    "objectID": "terms.html",
    "href": "terms.html",
    "title": "Glossary",
    "section": "",
    "text": "Learning a programming language is just like learning a spoken language: there are a lot of terms and definitions to learn! To complicate matters for an R / Python bilingualism context like this one, the two programming languages sometimes use the same term with very different definitions attached. To hopefully streamline term acquisition / comparison, I’m compiling a glossary of crucial R and Python terms below.\nNote that if a definition has a term in both languages, the definition is given with the terms in the respective languages beneath. If a term is only found in one language it is given first and subsequently defined."
  },
  {
    "objectID": "terms.html#overview",
    "href": "terms.html#overview",
    "title": "Glossary",
    "section": "",
    "text": "Learning a programming language is just like learning a spoken language: there are a lot of terms and definitions to learn! To complicate matters for an R / Python bilingualism context like this one, the two programming languages sometimes use the same term with very different definitions attached. To hopefully streamline term acquisition / comparison, I’m compiling a glossary of crucial R and Python terms below.\nNote that if a definition has a term in both languages, the definition is given with the terms in the respective languages beneath. If a term is only found in one language it is given first and subsequently defined."
  },
  {
    "objectID": "terms.html#general-terms",
    "href": "terms.html#general-terms",
    "title": "Glossary",
    "section": "General Terms",
    "text": "General Terms\n\nData stored for later re-use (regardless of structure/dimensions)\n\nPython Python – variable\nR Project R – object\n\nCategory of information stored in a given data variable/object\n\nPython Python – type\nR Project R – class\n\nDownloadable set of functions\n\nPython Python & R Project R – library / package\nSee “Tools” for definition of ‘function’"
  },
  {
    "objectID": "terms.html#data-typesclasses",
    "href": "terms.html#data-typesclasses",
    "title": "Glossary",
    "section": "Data Types/Classes",
    "text": "Data Types/Classes\n\nNumbers that are not a fraction (i.e., are a whole number)\n\nPython Python & R Project R – integer\nPython Python Pandas library – int64\n\nNon-integer numbers\n\nPython Python – float\nPython Python Pandas library – float64\nR Project R – numeric\n\nText / content stored as text\n\nPython Python – string\nPython Python Pandas library – object\nR Project R – character\n\nCategorical content with an order among the unique entries (often–though not necessarily–with few unique entries relative to total number of entries)\n\nR Project R ONLY – factor\n\nLogical values indicating whether conditions are met\n\nPython Python – boolean (True / False)\nR Project R – boolean (TRUE / FALSE / T / F)\n\nVariable/Object holding an ordered sequence of data (can be modified)\n\nPython Python – list\nR Project R – vector (must be one-dimensional) / list\n\nEach component of a list/list\n\nPython Python – item\nR Project R – element\n\nVariable holding an ordered sequence of data (cannot be modified)\n\nPython Python ONLY – tuple [too-pull]"
  },
  {
    "objectID": "terms.html#operators",
    "href": "terms.html#operators",
    "title": "Glossary",
    "section": "Operators",
    "text": "Operators\n\nAssignment operator – creates a new variable/object\n\nPython Python – =\nR Project R – &lt;- / -&gt;\n\nArithmetic operators – performs basic arithmetic\n\nPython Python & R Project R – addition (+)\nPython Python & R Project R – subtraction (-)\nPython Python & R Project R – multiplication (*)\nPython Python & R Project R – division (/)\nPython Python – exponent (**)\nR Project R – exponent (^)\n\nArithmetic assignment operator – does an arithmetic operation and stores the result in a variable\n\nPython Python ONLY – arithmetic operator and assignment operator (e.g., +=)\n\nRelational operators – conditional statements that return boolean values\n\nPython Python & R Project R – ‘exactly equal to’ (==)\nPython Python & R Project R – ‘not equal to’ (!=)\nPython Python & R Project R – greater/less than (&gt; / &lt; respectively)\nPython Python & R Project R – greater/less than or equal to (&gt;= / &lt;= respectively)\n\nNamespacing operator – specifies library in which a given function is defined\n\nPython Python – a period package.function\nR Project R – two colons package::function (optional)"
  },
  {
    "objectID": "terms.html#tools",
    "href": "terms.html#tools",
    "title": "Glossary",
    "section": "Tools",
    "text": "Tools\n\nVariable/Object containing multiple, inter-related operations that are run in a pre-defined order every time the variable/object is used\n\nPython Python & R Project R – function\n\nValue sent to a function when called to modify behavior (sometimes optional)\n\nPython Python & R Project R – argument / parameter\n\nFunction that can only be used on a specific type/class of variable/object that supports arguments (sometimes optional) to modify behavior\n\nPython Python – method (variable.method(...))\nR Project R – just a special case of function\n\nFunction that can only be used on a specific type/class of variable/object without arguments to modify behavior\n\nPython Python – attribute (variable.attribute)\nR Project R – just a special case of function"
  },
  {
    "objectID": "terms.html#data-characteristics",
    "href": "terms.html#data-characteristics",
    "title": "Glossary",
    "section": "Data Characteristics",
    "text": "Data Characteristics\n\nNumber of items/elements in a variable/object\n\nPython Python – length (len())\nR Project R – length (length())\n\nNumber of rows/columns in a two-dimension, tabular variable/object\n\nPython Python – shape (.shape)\nR Project R – dimensions (dim())\n\nNumber of characters in a string\n\nPython Python – also length (len())\nR Project R – number of characters (nchar())"
  },
  {
    "objectID": "dir_mgmt.html",
    "href": "dir_mgmt.html",
    "title": "Directory & File Management",
    "section": "",
    "text": "One thing we have not discussed that is incredibly important to any scripted language (Python Python or R Project R very much included) is computer directory and file management. Code often interacts with external data files that must be imported at the start of a workflow and often preserves a record of its operation as an exported product at the end of the workflow. These concepts are more related to fundamental understanding of how your computer stores information than they are strictly coding language considerations but they are still worth discussing here."
  },
  {
    "objectID": "dir_mgmt.html#overview",
    "href": "dir_mgmt.html#overview",
    "title": "Directory & File Management",
    "section": "",
    "text": "One thing we have not discussed that is incredibly important to any scripted language (Python Python or R Project R very much included) is computer directory and file management. Code often interacts with external data files that must be imported at the start of a workflow and often preserves a record of its operation as an exported product at the end of the workflow. These concepts are more related to fundamental understanding of how your computer stores information than they are strictly coding language considerations but they are still worth discussing here."
  },
  {
    "objectID": "dir_mgmt.html#crucial-vocabulary",
    "href": "dir_mgmt.html#crucial-vocabulary",
    "title": "Directory & File Management",
    "section": "Crucial Vocabulary",
    "text": "Crucial Vocabulary\nThere are a few vocabulary terms we need to introduce before we can dive into the code side of file and directory management. Fortunately, these are terms that apply to computers generally so we do not have to deal with Python Python and R Project R using different names for the same concept.\n\nDirectory – A folder on your computer (typically containing other folders and/or files) particular file/folder\nWorking Directory – The folder your code is “looking at” for a given project\n\nBy default this is the folder in which the code file itself can be found though you can set it elsewhere (though this is sometimes risky)\n\nRoot – The single folder that contains everything else on your computer\nAbsolute Path – The names of each directory beginning at the root and ending at a - Relative Path – The names of each directory beginning at the your working directory and ending at a particular file/folder"
  },
  {
    "objectID": "dir_mgmt.html#library-loading",
    "href": "dir_mgmt.html#library-loading",
    "title": "Directory & File Management",
    "section": "Library Loading",
    "text": "Library Loading\nWe’ll need to quickly load any needed libraries before getting into the “actual” coding.\n\nR Project RPython Python\n\n\nR does not require any libraries to perform these operations!\n\n\nWe’ll need the os library and glob library in Python to do these operations.\n\n# Load needed library\nimport os\nimport glob"
  },
  {
    "objectID": "dir_mgmt.html#the-working-directory",
    "href": "dir_mgmt.html#the-working-directory",
    "title": "Directory & File Management",
    "section": "The Working Directory",
    "text": "The Working Directory\nAs defined above, the working directory is the primary folder with which your code can easily interact. This includes folders within your working directory but does not include folders “above”/outside of it. It is a good practice to use different folders for different projects such that each project has a different working directory and you don’t run the risk of scripts/data from one project accidentally interacting with those form another project. For R Project R users, the RStudio “R Project” functionality guarantees that you have a different working directory for each R project.\nBoth languages provide a quick way of checking what your current working directory is to ensure you’re not accidentally in the wrong one. Note that either approach will return the absolute path to your working directory which will differ among users/computers.\n\nR Project RPython Python\n\n\nBase R includes the getwd function to display your current working directory.\n\n# Check current working directory\ngetwd()\n\n[1] \"/Users/lyon/Documents/NCEAS Content/lyon_bilingualism\"\n\n\n\n\n\n# Check current working directory\nos.getcwd()\n\n'/Users/lyon/Documents/NCEAS Content/lyon_bilingualism'"
  },
  {
    "objectID": "dir_mgmt.html#operating-systems-file-paths",
    "href": "dir_mgmt.html#operating-systems-file-paths",
    "title": "Directory & File Management",
    "section": "Operating Systems & File Paths",
    "text": "Operating Systems & File Paths\nOne minor–but often frustrating–hurdle for collaborative coding occurs when group members use different operating systems (i.e., macOS, Windows, etc.). When defining file paths (absolute or relative), different operating systems use either a slash (/) or a backslash (\\) to separate directories in that path. Unfortunately for us, your OS will only be able to interpret file paths that use the type of slash it uses. This means that any code that reads in external data or exports its outputs needs to account for this OS-level difference every time a file path is defined. However, the developers of Python Python and R Project R know this pain themselves and have given us straightforward tools to handle this.\n\nR Project RPython Python\n\n\nBase R includes a file.path function that automatically detects your computer’s OS and inserts the correct type of slash between each directory name.\n\n# Build a faux file path\nfile.path(\"path\", \"to\", \"my\", \"data\")\n\n[1] \"path/to/my/data\"\n\n\n\n\nThe os library in Python includes a join function that automatically detects your computer’s OS and inserts the correct type of slash between each directory name.\n\n# Build a faux file path\nos.path.join(\"path\", \"to\", \"my\", \"data\")\n\n'path/to/my/data'\n\n\nNote that the needed function is in the path module of the os library.\n\n\n\nUsing these tools allows us to code collaboratively even when not all group members use the same operating system! Note that nothing will solve the issue of using absolute paths because group members will always have different paths from the root to a particular directory. Because of this it is best to always use relative paths when working in group contexts."
  },
  {
    "objectID": "dir_mgmt.html#finding-files",
    "href": "dir_mgmt.html#finding-files",
    "title": "Directory & File Management",
    "section": "Finding Files",
    "text": "Finding Files\nOnce you’ve confirmed your working directory and figured out how to account for OS idiosyncrasies, its time to actually look at the files you have available! In the Terminal command line, the ls function lists all files in a particular folder. Fortunately both Python Python and R Project R contain tools for doing this as well.\n\nR Project RPython Python\n\n\nWe can use the base R dir function to identify all files in a particular folder (note this ignores folders in that folder).\n\n# List files in the \"data\" folder for this website\ndir(path = file.path(\"data\"))\n\n[1] \"mammals.sqlite\"  \"tree_lichen.csv\" \"tree_road.csv\"   \"verts.csv\"      \n\n\n\n\nWe can use the glob function (from the library of the same name) to identify all files in a particular folder.\n\n# List files in the \"data\" folder for this website\nglob.glob(pathname = os.path.join(\"data\", \"*\"))\n\n['data/tree_lichen.csv', 'data/verts.csv', 'data/tree_road.csv', 'data/mammals.sqlite']\n\n\nNote that we need to use the wildcard asterisk (*) to identify everything in the “data” folder."
  },
  {
    "objectID": "external-data.html",
    "href": "external-data.html",
    "title": "Starting with Data",
    "section": "",
    "text": "Begin by loading any needed libraries.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package.\n\n# Load needed library\nlibrary(tidyverse)\n\n\n\nLoad the Pandas and os libraries.\n\n# Load needed libraries\nimport os\nimport pandas as pd"
  },
  {
    "objectID": "external-data.html#library-loading",
    "href": "external-data.html#library-loading",
    "title": "Starting with Data",
    "section": "",
    "text": "Begin by loading any needed libraries.\n\nR Project RPython Python\n\n\nLoad the tidyverse meta-package.\n\n# Load needed library\nlibrary(tidyverse)\n\n\n\nLoad the Pandas and os libraries.\n\n# Load needed libraries\nimport os\nimport pandas as pd"
  },
  {
    "objectID": "external-data.html#data-import",
    "href": "external-data.html#data-import",
    "title": "Starting with Data",
    "section": "Data Import",
    "text": "Data Import\nWe can now load an external dataset derived from the lterdatasampler R package (see here) with both R and Python. This relatively simple operation is also a nice chance to showcase how ‘namespacing’ (i.e., indicating which package a given function comes from) differs between the two languages.\n\nR Project RPython Python\n\n\nNamespacing in R is accomplished by doing package_name::function_name and is optional (though, in my opinion, good practice!). Note that we use the assignment operator (&lt;-) to assign the contents of the CSV to an object.\n\n# Read in vertebrate data CSV\nvert_r &lt;- utils::read.csv(file = file.path(\"data\", \"verts.csv\"))\n\nRecall from our file path module that the file.path function accounts for computer operating system differences.\n\n\nIn Python, namespacing is required and is done via package_name.function_name. Note that we use the assignment operator (=) to assign the contents of the CSV to a variable.\n\n# Read in vertebrate data CSV\nvert_py = pd.read_csv(os.path.join(\"data\", \"verts.csv\"))\n\nRecall from our file path module that the join function accounts for computer operating system differences."
  },
  {
    "objectID": "external-data.html#tabular-data-typeclass",
    "href": "external-data.html#tabular-data-typeclass",
    "title": "Starting with Data",
    "section": "Tabular Data Type/Class",
    "text": "Tabular Data Type/Class\nData stored in CSVs (and similar data formats like Microsoft Excel, etc.) has a unique type/class that differs from some of the categories we covered in the “Fundamentals” section.\n\nR Project RPython Python\n\n\nIn R, such data are class data.frame\n\n# Check class of a data object\nclass(vert_r)\n\n[1] \"data.frame\"\n\n\n\n\nIn Python, such data are type DataFrame and this variable type is defined by the Pandas library. This is the standard type returned by the Pandas read_csv function.\n\n# Check type of a data object\ntype(vert_py)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;"
  },
  {
    "objectID": "external-data.html#making-heads-or-tails-of-data",
    "href": "external-data.html#making-heads-or-tails-of-data",
    "title": "Starting with Data",
    "section": "Making Heads or Tails of Data",
    "text": "Making Heads or Tails of Data\nChecking the ‘head’ or ‘tail’ of the data (i.e., the first or last few rows of the data respectively) is a nice way of getting a sense for the general format of the dataframe being assessed.\n\nR Project RPython Python\n\n\nIn R, we use the head or tail function to return the first or last rows respectively.\n\n# Check out head\n1utils::head(vert_r, n = 2)\n\n\n1\n\nNote that we’re using the optional n argument to specify the number of rows to return\n\n\n\n\n  year sitecode section reach pass unitnum unittype vert_index pitnumber\n1 1987 MACKCC-L      CC     L    1       1        R          1        NA\n2 1987 MACKCC-L      CC     L    1       1        R          2        NA\n          species length_1_mm length_2_mm weight_g clip sampledate notes\n1 Cutthroat trout          58          NA     1.75 NONE 1987-10-07      \n2 Cutthroat trout          61          NA     1.95 NONE 1987-10-07      \n\n\n\n# Check out tail\nutils::tail(vert_r, n = 3)\n\n      year sitecode section reach pass unitnum unittype vert_index pitnumber\n32207 2019 MACKOG-U      OG     U    2      16        C         24   1043547\n32208 2019 MACKOG-U      OG     U    2      16        C         25   1043583\n32209 2019 MACKOG-U      OG     U    2      16        C         26   1043500\n                       species length_1_mm length_2_mm weight_g clip sampledate\n32207 Coastal giant salamander          67         120      9.6 NONE 2019-09-05\n32208 Coastal giant salamander          74         131     14.3 NONE 2019-09-05\n32209 Coastal giant salamander          73         128     11.6 NONE 2019-09-05\n            notes\n32207            \n32208            \n32209 Terrestrial\n\n\n\n\nIn Python, we use the head or tail method to return the first or last rows respectively. Note that these methods are only available to variables of type DataFrame. All methods are appended to the end of the variable of the appropriate type separated by a period.\n\n# Check out head\nvert_py.head(3)\n\n   year  sitecode section reach  ...  weight_g  clip  sampledate  notes\n0  1987  MACKCC-L      CC     L  ...      1.75  NONE  1987-10-07    NaN\n1  1987  MACKCC-L      CC     L  ...      1.95  NONE  1987-10-07    NaN\n2  1987  MACKCC-L      CC     L  ...      5.60  NONE  1987-10-07    NaN\n\n[3 rows x 16 columns]\n\n\n\n# Check out tail\nvert_py.tail(2)\n\n       year  sitecode section reach  ...  weight_g  clip  sampledate        notes\n32207  2019  MACKOG-U      OG     U  ...      14.3  NONE  2019-09-05          NaN\n32208  2019  MACKOG-U      OG     U  ...      11.6  NONE  2019-09-05  Terrestrial\n\n[2 rows x 16 columns]"
  },
  {
    "objectID": "external-data.html#data-structure",
    "href": "external-data.html#data-structure",
    "title": "Starting with Data",
    "section": "Data Structure",
    "text": "Data Structure\nWhile it is nice to know the type/class of the data table generally, we often need to know the type/class of the columns within those data tables. Our operations are typically aimed at modifying particular columns and pre-requisite to that is knowing the type/class of the column to know what actions are available to us.\n\nR Project RPython Python\n\n\nR uses the str function to assess data structure. Structure includes the dimensions of the data (i.e., number of rows and columns) as well as the class of the data (data.frame) and the class of each column.\n\nutils::str(vert_r)\n\n'data.frame':   32209 obs. of  16 variables:\n $ year       : int  1987 1987 1987 1987 1987 1987 1987 1987 1987 1987 ...\n $ sitecode   : chr  \"MACKCC-L\" \"MACKCC-L\" \"MACKCC-L\" \"MACKCC-L\" ...\n $ section    : chr  \"CC\" \"CC\" \"CC\" \"CC\" ...\n $ reach      : chr  \"L\" \"L\" \"L\" \"L\" ...\n $ pass       : int  1 1 1 1 1 1 1 1 1 1 ...\n $ unitnum    : num  1 1 1 1 1 1 1 1 1 1 ...\n $ unittype   : chr  \"R\" \"R\" \"R\" \"R\" ...\n $ vert_index : int  1 2 3 4 5 6 7 8 9 10 ...\n $ pitnumber  : int  NA NA NA NA NA NA NA NA NA NA ...\n $ species    : chr  \"Cutthroat trout\" \"Cutthroat trout\" \"Cutthroat trout\" \"Cutthroat trout\" ...\n $ length_1_mm: int  58 61 89 58 93 86 107 131 103 117 ...\n $ length_2_mm: int  NA NA NA NA NA NA NA NA NA NA ...\n $ weight_g   : num  1.75 1.95 5.6 2.15 6.9 5.9 10.5 20.6 9.55 13 ...\n $ clip       : chr  \"NONE\" \"NONE\" \"NONE\" \"NONE\" ...\n $ sampledate : chr  \"1987-10-07\" \"1987-10-07\" \"1987-10-07\" \"1987-10-07\" ...\n $ notes      : chr  \"\" \"\" \"\" \"\" ...\n\n\nBe careful to not confuse this with the Python function str that coerces values to type “string”!\n\n\nWhen we want to know the type of each column in a Python DataFrame, we can use the dtypes “attribute”. Attributes are akin to a method but they completely lack arguments that might modify their behavior. As a consequence they are extremely precisely defined. The dtypes attribute returns the type of each column.\n\nvert_py.dtypes\n\nyear             int64\nsitecode        object\nsection         object\nreach           object\npass             int64\nunitnum        float64\nunittype        object\nvert_index       int64\npitnumber      float64\nspecies         object\nlength_1_mm    float64\nlength_2_mm    float64\nweight_g       float64\nclip            object\nsampledate      object\nnotes           object\ndtype: object"
  },
  {
    "objectID": "external-data.html#data-summaries",
    "href": "external-data.html#data-summaries",
    "title": "Starting with Data",
    "section": "Data Summaries",
    "text": "Data Summaries\nWe often want to begin our exploration of a given dataset by getting a summary of each column. This is rarely what we actually need for statistics or visualization but it is a nice high-level way of getting a sense for the composition of the data.\n\nR Project RPython Python\n\n\nR provides the summary function to summarize all columns in a dataset. Note that it is not terribly informative for columns of class character.\n\n# Get summary of data\nsummary(vert_r)\n\n      year        sitecode           section             reach          \n Min.   :1987   Length:32209       Length:32209       Length:32209      \n 1st Qu.:1998   Class :character   Class :character   Class :character  \n Median :2006   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2005                                                           \n 3rd Qu.:2012                                                           \n Max.   :2019                                                           \n                                                                        \n      pass          unitnum         unittype           vert_index    \n Min.   :1.000   Min.   : 1.000   Length:32209       Min.   :  1.00  \n 1st Qu.:1.000   1st Qu.: 3.000   Class :character   1st Qu.:  5.00  \n Median :1.000   Median : 7.000   Mode  :character   Median : 13.00  \n Mean   :1.224   Mean   : 7.696                      Mean   : 20.17  \n 3rd Qu.:1.000   3rd Qu.:11.000                      3rd Qu.: 27.00  \n Max.   :2.000   Max.   :20.000                      Max.   :147.00  \n                                                                     \n   pitnumber          species           length_1_mm      length_2_mm   \n Min.   :   62048   Length:32209       Min.   : 19.00   Min.   : 28.0  \n 1st Qu.:13713632   Class :character   1st Qu.: 47.00   1st Qu.: 77.0  \n Median :18570447   Mode  :character   Median : 63.00   Median : 98.0  \n Mean   :16286432                      Mean   : 73.83   Mean   :100.5  \n 3rd Qu.:19132429                      3rd Qu.: 97.00   3rd Qu.:119.0  \n Max.   :28180046                      Max.   :253.00   Max.   :284.0  \n NA's   :26574                         NA's   :17       NA's   :19649  \n    weight_g           clip            sampledate           notes          \n Min.   :  0.090   Length:32209       Length:32209       Length:32209      \n 1st Qu.:  1.510   Class :character   Class :character   Class :character  \n Median :  6.050   Mode  :character   Mode  :character   Mode  :character  \n Mean   :  8.903                                                           \n 3rd Qu.: 11.660                                                           \n Max.   :134.590                                                           \n NA's   :13268                                                             \n\n\n\n\nPython has the describe method for getting similar information about each column of a DataFrame.\n\n# Describe data\nvert_py.describe()\n\n               year          pass  ...   length_2_mm      weight_g\ncount  32209.000000  32209.000000  ...  12560.000000  18941.000000\nmean    2004.917601      1.223664  ...    100.485191      8.902859\nstd        8.572474      0.416706  ...     34.736955     10.676276\nmin     1987.000000      1.000000  ...     28.000000      0.090000\n25%     1998.000000      1.000000  ...     77.000000      1.510000\n50%     2006.000000      1.000000  ...     98.000000      6.050000\n75%     2012.000000      1.000000  ...    119.000000     11.660000\nmax     2019.000000      2.000000  ...    284.000000    134.590000\n\n[8 rows x 8 columns]\n\n\nPython also offers the info method to identify only the count of non-null entries in each column as well as the type of each column.\n\n# Check info of data\nvert_py.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 32209 entries, 0 to 32208\nData columns (total 16 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   year         32209 non-null  int64  \n 1   sitecode     32209 non-null  object \n 2   section      32209 non-null  object \n 3   reach        32209 non-null  object \n 4   pass         32209 non-null  int64  \n 5   unitnum      32209 non-null  float64\n 6   unittype     31599 non-null  object \n 7   vert_index   32209 non-null  int64  \n 8   pitnumber    5635 non-null   float64\n 9   species      32206 non-null  object \n 10  length_1_mm  32192 non-null  float64\n 11  length_2_mm  12560 non-null  float64\n 12  weight_g     18941 non-null  float64\n 13  clip         32209 non-null  object \n 14  sampledate   32209 non-null  object \n 15  notes        3174 non-null   object \ndtypes: float64(5), int64(3), object(8)\nmemory usage: 3.9+ MB"
  },
  {
    "objectID": "external-data.html#identifying-columns",
    "href": "external-data.html#identifying-columns",
    "title": "Starting with Data",
    "section": "Identifying Columns",
    "text": "Identifying Columns\nIf we want to skip these steps and just identify the full set of column labels/names there is a small operation for stripping that information out in both languages.\n\nR Project RPython Python\n\n\nR has the names function to quickly return a vector of the column names in a given data.frame object.\n\n# Check column names\nnames(vert_r)\n\n [1] \"year\"        \"sitecode\"    \"section\"     \"reach\"       \"pass\"       \n [6] \"unitnum\"     \"unittype\"    \"vert_index\"  \"pitnumber\"   \"species\"    \n[11] \"length_1_mm\" \"length_2_mm\" \"weight_g\"    \"clip\"        \"sampledate\" \n[16] \"notes\"      \n\n\n\n\nPython has the columns attributes for returning a simple list of column labels in a given DataFrame variable.\n\n# Check column labels\nvert_py.columns\n\nIndex(['year', 'sitecode', 'section', 'reach', 'pass', 'unitnum', 'unittype',\n       'vert_index', 'pitnumber', 'species', 'length_1_mm', 'length_2_mm',\n       'weight_g', 'clip', 'sampledate', 'notes'],\n      dtype='object')"
  },
  {
    "objectID": "external-data.html#accessing-columns",
    "href": "external-data.html#accessing-columns",
    "title": "Starting with Data",
    "section": "Accessing Column(s)",
    "text": "Accessing Column(s)\nWe may want to access a particular column or set of columns. There are several approaches we might use to access a particular column in either Python or R. They are:\n\nIndexing the column by its location\nIndexing the column by its label/name\nIndexing the column with an operator\n\nIn all of the following examples we’ll use the head method/function to simplify the output.\n\nR Project RPython Python\n\n\nIf we know the order of the columns we can use the same syntax as when we indexed a vector.\n\n# Use column indexing\nhead(vert_r[1])\n\n  year\n1 1987\n2 1987\n3 1987\n4 1987\n5 1987\n6 1987\n\n\nNote that if we also want to account for rows we would put the desired column number on the right and the desired row number on the left.\n\n# Use row/column indexing\nhead(vert_r[, 1])\n\n[1] 1987 1987 1987 1987 1987 1987\n\n\nIf preferred we could instead substitute the number for the column name.\n\nhead(vert_r[\"year\"])\n\n  year\n1 1987\n2 1987\n3 1987\n4 1987\n5 1987\n6 1987\n\n\nIn R, the column operator is a $ and we place that character between the object and column names (e.g., data_name$column_name).\n\nhead(vert_r$year)\n\n[1] 1987 1987 1987 1987 1987 1987\n\n\n\n\nIf we know the index position of the desired column we can use the iloc method (short for “integer location”). Note that the iloc method uses square brackets instead of parentheses (typical methods use parentheses). We must include a colon with either nothing or the start/stop bounds (see “Slicing” in “Fundamentals”). A colon without specifying bounds returns all rows.\n\n# Use row/column indexing\nvert_py.iloc[: , 0].head()\n\n0    1987\n1    1987\n2    1987\n3    1987\n4    1987\nName: year, dtype: int64\n\n\nIf preferred we could instead substitute the number for the column label.\n\nvert_py[\"year\"].head()\n\n0    1987\n1    1987\n2    1987\n3    1987\n4    1987\nName: year, dtype: int64\n\n\nIn R, the column operator is a . and we place that character between the variable name and column label (e.g., data_name.column_name).\n\nvert_py.year.head()\n\n0    1987\n1    1987\n2    1987\n3    1987\n4    1987\nName: year, dtype: int64\n\n\n\n\n\nWhen we want to access multiple columns we can still use either index positions or column labels/names but we cannot use the column operator.\nWe’ll continue to use the head method/function to simplify outputs.\n\nR Project RPython Python\n\n\nIn R we could use a concatenated vector of index positions to specify particular columns by their positions.\n\n# Use multiple column index positions\nhead(vert_r[, c(1:2, 13)])\n\n  year sitecode weight_g\n1 1987 MACKCC-L     1.75\n2 1987 MACKCC-L     1.95\n3 1987 MACKCC-L     5.60\n4 1987 MACKCC-L     2.15\n5 1987 MACKCC-L     6.90\n6 1987 MACKCC-L     5.90\n\n\nInstead we could use a vector of column names for extra precision.\n\n# Use multiple column names\nhead(vert_r[, c(\"year\", \"sitecode\", \"weight_g\")])\n\n  year sitecode weight_g\n1 1987 MACKCC-L     1.75\n2 1987 MACKCC-L     1.95\n3 1987 MACKCC-L     5.60\n4 1987 MACKCC-L     2.15\n5 1987 MACKCC-L     6.90\n6 1987 MACKCC-L     5.90\n\n\n\n\nIn Python we could use the iloc method for multiple columns and simply supply a list of the column index positions in which we are interested. Note that this method is different from many of the other methods we’ve covered so far because it uses square brackets instead of parentheses.\n\n# Use multiple column index positions\nvert_py.iloc[:, [0, 1, 12]].head()\n\n   year  sitecode  weight_g\n0  1987  MACKCC-L      1.75\n1  1987  MACKCC-L      1.95\n2  1987  MACKCC-L      5.60\n3  1987  MACKCC-L      2.15\n4  1987  MACKCC-L      6.90\n\n\nOr we could use the .loc method and supply a list of column labels. Note that the loc method also uses square brackets instead of parentheses and requires a colon to the left of the comma in order to return all rows.\n\nvert_py.loc[:, [\"year\", \"sitecode\", \"weight_g\"]].head()\n\n   year  sitecode  weight_g\n0  1987  MACKCC-L      1.75\n1  1987  MACKCC-L      1.95\n2  1987  MACKCC-L      5.60\n3  1987  MACKCC-L      2.15\n4  1987  MACKCC-L      6.90"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "I think of myself as a competent R coder but am a total novice when it comes to Python. This repository is my attempt at forcing myself to ‘eat my vegetables’ and gain basic competency in Python. I think trying for a 1-to-1 R translation to Python will be an effective learning method (at least to start) and enshrining it in a Quarto website will keep me rigorous about documenting my process."
  },
  {
    "objectID": "index.html#package-installation",
    "href": "index.html#package-installation",
    "title": "Welcome!",
    "section": "Package Installation",
    "text": "Package Installation\nBoth coding languages rely on packages to install specific functions that are absent from the ‘base’ version of either Python Python or R Project R. The following code chunks are not evaluated in the building of this website but you’ll need to install these packages on your local machine (if you haven’t already done so) in order to run the code in the rest of this translation tutorial.\n\nR Project RPython Python\n\n\nR contains an install.packages function for installing packages from within R.\n\n# Install the 'tidyverse' meta-package\ninstall.packages(\"tidyverse\")\ninstall.packages(\"DBI\")\n\n\n\nPython packages must be installed via the Command Line Interface (a.k.a. CLI, or “bash”).\n\n# Install the following python packages\npython3 -m pip install pandas\npython3 -m pip install numpy\npython3 -m pip install matplotlib\npython3 -m pip install jupyterlab\npython3 -m pip install sqlite3\n\n## `plotnine` is `ggplot2` in python!\npython3 -m pip install plotnine"
  },
  {
    "objectID": "index.html#section-overviews",
    "href": "index.html#section-overviews",
    "title": "Welcome!",
    "section": "Section Overviews",
    "text": "Section Overviews\n\nFundamentals\nWhen learning a new programming language, it can be really helpful to begin with dramatically simplified examples to demonstrate crucial concepts. We can also build upon really core concepts into more nuanced fundamentals like automation or string/character methods.\n\n\nData Wrangling\nThe beating heart of my day-to-day work revolves around data ‘wrangling’. I view ‘wrangling’ as any scripted data manipulations between the very first raw data entered digitally and the data being ready for any analysis/visualization. This covers a huge swath of operations and should allow me to explore Python equivalents to many of the R operations that I know and love.\n\n\nVisualization\nSomewhat self-explanatory but this section is all about data visualization! While visualization can be an effective quality control tool it is also useful in data exploration and–eventually–to generate publication- or report-quality graphics. This section attempts to cover the fundamentals of data “viz” in both languages but is by no means exhaustive!\n\n\nSQL\nDatabase SQL is a powerful programming language in its own right that is intended to work with relational databases. Relational databases include several data tables of various sizes/structures that share some common ‘index’ columns that allow them to be combined as needed. Both Python Python and R Project R allow users to access these databases using Database SQL syntax while still living in their preferred coding language. This section highlights some of the major considerations when working with databases through either language though it is not a tutorial on Database SQL’s syntax itself.\n\n\nGlossary\nAs the heading would suggest, I’m housing various term definitions here. As of now, it makes most sense to me to provide the definition for a concept and then give the term in Python Python & R Project R. Note that I also give a more functional definition of major concepts in the code tutorial pages upon first mention."
  },
  {
    "objectID": "index.html#contributing-guidelines",
    "href": "index.html#contributing-guidelines",
    "title": "Welcome!",
    "section": "Contributing Guidelines",
    "text": "Contributing Guidelines\n\nContributing Overview\nA comprehensive and accessible coding bilingualism website like this one is a huge undertaking and I’d welcome collaborators who share my vision for the value of a resource like this. I’m a competent R coder but that definitely does not mean I am 100% correct all the time nor that I always write explanations in the clearest way possible. On the Python front, I’m a total novice and my approach to this website has largely involved reframing and recapitulating my takeaways from the tutorials that I’ve taken.\nSo, if you’d like to collaborate with me on this I have drafted the following guidelines. I’m happy to discuss/modify these with prospective collaborators so please don’t let them dissuade you from reaching out!\n\n\nBug / Issue Reporting\nIf you see something wrong–either in a code chunk or in the plain text–I’d really appreciate it if you flagged it for my attention. You can do this by opening a  GitHub Issue on this project’s repository. Please include the link to the page with the problem and as much detail as possible so I can easily find the problem area and make any needed repairs.\nIf you identify a bug in this manner I’ll add your name (and the link to the professional website of your choosing) to the list below!\n\nBug Finders \n\n\n\n\n\n\nCo-Development\nIf you’d like to actively collaborate with me on developing and refining this website that would be awesome! Please either reach out to me directly (see my website for my contact info) or open a  GitHub Issue to get that conversation started.\nI’m envisioning that each new collaborator would (1) fork the website’s GitHub repository, (2) make any edits that they had in mind, and (3) then submit a pull request to get those changes integrated into the primary website. I feel this minimizes the risk that changes have unintentional consequences for the website rendering as whole. I’m absolutely open to a branch-based alternative if that makes more sense and I anticipate refining the logistical elements of contributing once the development team grows somewhat.\n\n\nContribution Credit\nIf you are interested/willing to join me in refining this website, I believe that is absolutely worthy of formal credit. You’ll notice that the top right of the navbar has a “Creators” dropdown menu. If you contribute substantively (e.g., demonstrating new tools, adding a new page, etc.) we can add your name to the dropdown and link it to the professional website of your choosing.\nIf you have other modes of properly acknowledging your contribution(s) in mind I am absolutely open to discussing those ideas!"
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "Welcome!",
    "section": "Additional Resources",
    "text": "Additional Resources\nI’m not the first to have this idea so there are other useful Python tutorials and specifically R-Python bilingualism resources. See below:\n\nThe Carpentries has a “Data Analysis and Visualization in Python for Ecologists” lesson that is really well put-together (as is characteristic of The Carpentries’ content)\nThe Earth Lab has a Python course that was recommended to me by an NCEAS employee (specifically section 4)\nThe EEOB-BioData faculty at Iowa State University offer a “Computational Skills For Biological Data” course that covers R and Python (and Unix)\nDr. Diba Mirza taught a UCSB Computer Science (CS8) course on Python\nESIIL (Environmental Data Science Innovation and Inclusion Lab) has created an R-Python bilingualism tutorial that is framed for a more applied audience\nMarie Rivers also made a website for exploring Quarto more generally that I’ve found super helpful for the part of it that deals with R/Python bilingualism"
  },
  {
    "objectID": "collabs.html",
    "href": "collabs.html",
    "title": "R / Python Bilingualism",
    "section": "",
    "text": "Contributing Overview\nA comprehensive and accessible coding bilingualism website like this one is a huge undertaking and I’d welcome collaborators who share my vision for the value of a resource like this. I’m a competent R coder but that definitely does not mean I am 100% correct all the time nor that I always write explanations in the clearest way possible. On the Python front, I’m a total novice and my approach to this website has largely involved reframing and recapitulating my takeaways from the tutorials that I’ve taken.\nSo, if you’d like to collaborate with me on this I have drafted the following guidelines. I’m happy to discuss/modify these with prospective collaborators so please don’t let them dissuade you from reaching out!\n\n\nBug / Issue Reporting\nIf you see something wrong–either in a code chunk or in the plain text–I’d really appreciate it if you flagged it for my attention. You can do this by opening a  GitHub Issue on this project’s repository. Please include the link to the page with the problem and as much detail as possible so I can easily find the problem area and make any needed repairs.\nIf you identify a bug in this manner I’ll add your name (and the link to the professional website of your choosing) to the list below!\n\nBug Finders \n\n\n\n\n\n\nCo-Development\nIf you’d like to actively collaborate with me on developing and refining this website that would be awesome! Please either reach out to me directly (see my website for my contact info) or open a  GitHub Issue to get that conversation started.\nI’m envisioning that each new collaborator would (1) fork the website’s GitHub repository, (2) make any edits that they had in mind, and (3) then submit a pull request to get those changes integrated into the primary website. I feel this minimizes the risk that changes have unintentional consequences for the website rendering as whole. I’m absolutely open to a branch-based alternative if that makes more sense and I anticipate refining the logistical elements of contributing once the development team grows somewhat.\n\n\nContribution Credit\nIf you are interested/willing to join me in refining this website, I believe that is absolutely worthy of formal credit. You’ll notice that the top right of the navbar has a “Creators” dropdown menu. If you contribute substantively (e.g., demonstrating new tools, adding a new page, etc.) we can add your name to the dropdown and link it to the professional website of your choosing.\nIf you have other modes of properly acknowledging your contribution(s) in mind I am absolutely open to discussing those ideas!"
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Core Concepts",
    "section": "",
    "text": "This section covers some of the most fundamental operations of both languages. These include variable/object assignment, data type/class, arithmetic, etc. External data are not included in this page.\nNote that any line in a code chunk preceded by a hashtag (#) is a “comment” and is not evaluated in either language. Including comments is generally good practice because it allows humans to read and understand code that may otherwise be unclear to them."
  },
  {
    "objectID": "basics.html#overview",
    "href": "basics.html#overview",
    "title": "Core Concepts",
    "section": "",
    "text": "This section covers some of the most fundamental operations of both languages. These include variable/object assignment, data type/class, arithmetic, etc. External data are not included in this page.\nNote that any line in a code chunk preceded by a hashtag (#) is a “comment” and is not evaluated in either language. Including comments is generally good practice because it allows humans to read and understand code that may otherwise be unclear to them."
  },
  {
    "objectID": "basics.html#assignment",
    "href": "basics.html#assignment",
    "title": "Core Concepts",
    "section": "Assignment",
    "text": "Assignment\nAt its most basic, we want to store data in code in such a way that we can use / manipulate it via our scripts. This requires assigning data to a variable/object with the assignment operator.\n\nR Project RPython Python\n\n\nIn R, the assignment operator is &lt;-. To use it, the name of the new object-to-be is on the left of the arrow and the information to assign is on the right.\n\n# Make a simple object\na &lt;- 2\n\n# Check it out\na\n\n[1] 2\n\n\n\n\nIn Python, the assignment operator is =. To use it, the name of the new object-to-be is on the left of the equal sign and the information to assign is on the right.\n\n# Make a simple object\na = 2\n\n# Check it out\na\n\n2\n\n\n\n\n\nOnce we’ve created a variable/object we can then use the information stored inside of it in downstream operations! For example, we could perform basic arithmetic on our variable/object and assign the result to a new variable/object.\n\nR Project RPython Python\n\n\nAddition, subtraction, multiplication, and division share operators across both languages (+, -, *, and / respectively). However, in R exponents use ^.\n\n# Raise to an exponent\nb &lt;- a^3\n\n# Check out the result\nb\n\n[1] 8\n\n\n\n\nAddition, subtraction, multiplication, and division share operators across both languages (+, -, *, and / respectively). However, in Python exponents use **\n\n# Raise to an exponent\nb = a**3\n\n# Check out the result\nb\n\n8"
  },
  {
    "objectID": "basics.html#type-class",
    "href": "basics.html#type-class",
    "title": "Core Concepts",
    "section": "Type & Class",
    "text": "Type & Class\nSome operations are only possible on some categories of information. For instance, we can only perform arithmetic on numbers. In Python this is known as the variable’s type & while in R this is the object’s class. In either case, it’s important to know–and be able to check–this information about the variables/objects with which we are working.\n\nR Project RPython Python\n\n\nIn R we use the class function to get this information. Note that the names of R classes sometimes differ from their equivalents in Python.\n\n# Check class of an integer\nclass(37)\n\n[1] \"numeric\"\n\n\n\n# Check class of a decimal\nclass(3.14159)\n\n[1] \"numeric\"\n\n\n\n# Check class of text\nclass(\"my hands are typing words\")\n\n[1] \"character\"\n\n\n\n\nIn python, the type function returns the type of the data object. Note that the names of Python types sometimes differ from their equivalents in R.\n\n# Check type of an integer\ntype(37)\n\n&lt;class 'int'&gt;\n\n\n\n# Check type of a decimal\ntype(3.14159)\n\n&lt;class 'float'&gt;\n\n\n\n# Check type of text\ntype(\"my hands are typing words\")\n\n&lt;class 'str'&gt;"
  },
  {
    "objectID": "basics.html#indexing",
    "href": "basics.html#indexing",
    "title": "Core Concepts",
    "section": "Indexing",
    "text": "Indexing\nWhen our variables/objects have more than one item/element we may want to examine the piece of information at a specific position. This position is the “index position” and can be accessed in either language fairly easily.\nIn order to explore this more fully, let’s make some example multi-component variables/objects.\n\nR Project RPython Python\n\n\nIn R, one of the fundamental data structures is a “vector”. Vectors are assembled with the concatenation function (c) where each item is separated by commas (,) and the set of them is wrapped in parentheses ((...)).\nNote that the class of the object comes from the vector’s contents rather than the fact that it is a vector. All elements in a vector therefore must share a class.\n\n# Make a multi-item variable\nx &lt;- c(1, 2, 3, 4, 5)\n\n# Check it out\nclass(x)\n\n[1] \"numeric\"\n\n\n\n\nIn Python the fundamental data structure is a “list”. Lists are assembled either by wrapping the items to include in square brackets ([...]) or by using the list function. In either case, each item is separated from the others by commas (,).\nNote that the type of the variable comes from the list itself rather than its contents. Lists therefore support items of multiple different types.\n\n# Make a multi-item variable\nx = [1, 2, 3, 4, 5]\n\n# Check it out\ntype(x)\n\n&lt;class 'list'&gt;\n\n\n\n\n\nOne crucial difference between R and Python is that Python is “0-based” meaning that the first item is at index position 0 while in R the position of the equivalent element is 1.\nFortunately, in either language the syntax for indexing is the same.\n\nR Project RPython Python\n\n\nTo index a multi-element object, simply append square brackets to the end of the object name and specify the number of the index position in which you are interested.\n\n# Access the first element of the vector\nx[1]\n\n[1] 1\n\n\n\n\nTo index a multi-item variable, simply append square brackets to the end of the variable name and specify the number of the index position in which you are interested.\n\n# Access the first item of the list\nx[0]\n\n1"
  },
  {
    "objectID": "basics.html#slicing",
    "href": "basics.html#slicing",
    "title": "Core Concepts",
    "section": "Slicing",
    "text": "Slicing\nWhen we index more than one position, this is known as “slicing”. We can still use square brackets in either language to slice multiple items/elements and the syntax inside of those brackets seems shared but yields different results due to inherent syntactical differences.\n\nR Project RPython Python\n\n\nIn R, when we write two numbers separated by a colon (:), that indicates that we want those two numbers and all integers between them.\n\n# Demonstrate that the colon is shorthand for 'all numbers between'\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWe can use this to slice out multiple continuous index positions from an object.\n\n# Slice items in the `x` object\nx[2:4]\n\n[1] 2 3 4\n\n\n\n\nIn order to slice in Python, we include the start and stop bounds of the items that we want to slice separated by a colon (:) inside of square brackets. The first bound (i.e., bound position 0) is actually the starting bracket of the list! This means that we can treat the first number in the slice in the same way we would in single indexing but the second number is actually the bound before the item with that index value.\nAnother way of thinking about this is that it is similar to a mathematical set. The starting bound is inclusive while the ending bound is exclusive.\n\n# Strip out several items of the Python list\nx[2:4]\n\n[3, 4]\n\n\nNotice that we only get the items at third and fourth index position despite 4 being after the colon (which in an index would return the fifth index position)? That is because the fourth bound is after the fourth item but before the fifth item."
  },
  {
    "objectID": "viz_gg.html",
    "href": "viz_gg.html",
    "title": "Visualizing Data",
    "section": "",
    "text": "Both Python Python and R Project R have a plotting library based on The Grammar of Graphics by Leland Wilkinson. The Python Python package (plotnine) is actually directly based on the R Project R package (ggplot2) so their internal syntax is very similar. In fact the only serious differences between the two languages’ ggplot operations are those that derive from larger syntax and format differences.\nNote that in the following examples we will not namespace R Project R ggplot2 functions (e.g., ggplot2::aes) for convenience. Any function not namespaced in the R examples producing graphs can be assumed to be exported from ggplot2."
  },
  {
    "objectID": "viz_gg.html#grammar-of-graphics",
    "href": "viz_gg.html#grammar-of-graphics",
    "title": "Visualizing Data",
    "section": "",
    "text": "Both Python Python and R Project R have a plotting library based on The Grammar of Graphics by Leland Wilkinson. The Python Python package (plotnine) is actually directly based on the R Project R package (ggplot2) so their internal syntax is very similar. In fact the only serious differences between the two languages’ ggplot operations are those that derive from larger syntax and format differences.\nNote that in the following examples we will not namespace R Project R ggplot2 functions (e.g., ggplot2::aes) for convenience. Any function not namespaced in the R examples producing graphs can be assumed to be exported from ggplot2."
  },
  {
    "objectID": "viz_gg.html#library-data-loading",
    "href": "viz_gg.html#library-data-loading",
    "title": "Visualizing Data",
    "section": "Library & Data Loading",
    "text": "Library & Data Loading\nBegin by loading any needed libraries and reading in an external data file for use in downstream examples.\n\nR Project RPython Python\n\n\nLoad the ggplot2 and dplyr libraries as well as our vertebrate data.\n\n# Load needed library\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load data\nvert_r &lt;- utils::read.csv(file = file.path(\"data\", \"verts.csv\"))\n\n# Keep only rows where species and year are *not* NA\ncomplete_r &lt;- dplyr::filter(.data = vert_r,\n                            !is.na(species) & nchar(species) != 0 &\n                              !is.na(year) & nchar(year) != 0)\n\n# Group data by species and year\ngrp_r &lt;- dplyr::group_by(.data = complete_r, \n                         year, species)\n\n# Average weight by species and year\navg_r &lt;- dplyr::summarize(.data = grp_r, \n                          mean_wt = mean(weight_g, na.rm = T))\n\n# Check out first few rows\nhead(avg_r, n = 5)\n\n# A tibble: 5 × 3\n# Groups:   year [5]\n   year species         mean_wt\n  &lt;int&gt; &lt;chr&gt;             &lt;dbl&gt;\n1  1987 Cutthroat trout    8.96\n2  1988 Cutthroat trout   16.1 \n3  1989 Cutthroat trout   14.3 \n4  1990 Cutthroat trout   11.2 \n5  1991 Cutthroat trout    9.15\n\n\nRemember that we use an ! in R to negate a conditional masking function like is.na.\nNote that the summarize function drops columns that it doesn’t create and that are not used as grouping variables.\n\n\nLoad the Plotnine, os, and Pandas libraries as well as our vertebrate data.\n\n# Load needed library\nimport os\nimport plotnine as p9\nimport pandas as pd\n\n# Load data\nvert_py = pd.read_csv(os.path.join(\"data\", \"verts.csv\"))\n\n# Keep only rows where species and year are *not* NA\ncomplete_py = vert_py[(~pd.isnull(vert_py[\"species\"])) & (~pd.isnull(vert_py[\"year\"]))]\n\n# Group data by species and year\ngrp_py = complete_py.groupby([\"year\", \"species\"])\n\n# Average weight by species and year\navg_py = grp_py[\"weight_g\"].mean().reset_index(name = \"mean_wt\")\n\n# Check out first few rows\navg_py.head()\n\n   year          species    mean_wt\n0  1987  Cutthroat trout   8.959867\n1  1988  Cutthroat trout  16.073510\n2  1989  Cutthroat trout  14.308766\n3  1990  Cutthroat trout  11.212827\n4  1991  Cutthroat trout   9.150639\n\n\nRemember that we use a ~ in Python to negate a conditional masking function like isnull."
  },
  {
    "objectID": "viz_gg.html#core-components",
    "href": "viz_gg.html#core-components",
    "title": "Visualizing Data",
    "section": "Core Components",
    "text": "Core Components\nThere are three fundamental components to ggplots:\n\nData variable(s)/object(s) used in the graph\nAesthetics (i.e., which column labels/names are assigned to graph components)\nGeometries (i.e., defining the type of plot)\n\n\nData & Aesthetics\nWe can create an empty graph with correctly labeled axes but without any data by defining the data and aesthetics but neglecting to include any geometry. Make a graph where year is on the X-axis (horizontal) and mean weight is on the Y-axis (vertical).\n\nR Project RPython Python\n\n\nColumn names cannot be in quotes in the aes function.\n\n# Create graph\nggplot(data = avg_r, mapping = aes(x = year, y = mean_wt))\n\n\n\n\n\n\nColumn labels supplies to the aes function need to be in quotes.\n\n# Create graph\n(p9.ggplot(data = avg_py, mapping = p9.aes(x = \"year\", y = \"mean_wt\")))\n\n&lt;Figure Size: (1280 x 960)&gt;\n\n\n\n\n\nNote that we need to wrap our Python ggplot in parentheses to avoid errors.\n\n\n\nAs we alluded to above, the ggplot function with data and mapped aesthetics is enough to create the correct axis labels and tick marks but doesn’t actually put our data on the graphing area. For that, we’ll need to add a geometry.\n\n\nGeometries\nAll geometry functions–in either language–take the form of geom_* where * is name of the desired chart type (e.g., geom_line adds a line, geom_bar adds bars, etc.). In order to add geometries onto our plot–again, in either language–we use the + operator. Note that style guides suggest ending each line of a ggplot with a + and including each new component as their own line below. This keeps even very complicated graphs relatively human-readable.\nLet’s make these graphs into scatter plots by adding a point geometry.\n\nR Project RPython Python\n\n\n\n# Create graph\nggplot(data = avg_r, mapping = aes(x = year, y = mean_wt)) +\n  geom_point()\n\n\n\n\n\n\n\n# Create graph\n(p9.ggplot(data = avg_py, mapping = p9.aes(x = \"year\", y = \"mean_wt\")) +\n    p9.geom_point()\n    )\n\n&lt;Figure Size: (1280 x 960)&gt;\n\n\n\n\n\n\n\n\nNote that in either language the geom_point function does not need either data or aesthetics because it “inherits” them from the ggplot function! You can specify aesthetics (or data!) for a particular geometry but it is simpler to specify it once if you’re okay with all subsequent plot components using the same data/aesthetics.\nLet’s practice a little further by making the color of the points dependent upon species.\n\nR Project RPython Python\n\n\n\n# Create graph\nggplot(data = avg_r, mapping = aes(x = year, y = mean_wt)) +\n  geom_point(mapping = aes(color = species))\n\n\n\n\nNote that we could specify the color aesthetic in the ggplot aesthetics!\n\n\n\n# Create graph\n(p9.ggplot(data = avg_py, mapping = p9.aes(x = \"year\", y = \"mean_wt\")) +\n    p9.geom_point(mapping = p9.aes(color = \"species\"))\n    )\n\n&lt;Figure Size: (1280 x 960)&gt;\n\n\n\n\n\nNote that we could specify the color aesthetic in the ggplot aesthetics!\n\n\n\n\n\nIterative Revision\nOne of the real strengths of ggplots is that you can preserve part of your ideal graph as a variable/object and then add to it later. This saves you from needing to re-type a consistent ggplot function when all you really want to do is experiment with different geometries\n\nR Project RPython Python\n\n\nCreate the top level of the graph and assign it to an object. Then–separately–add a line geometry.\n\n# Create graph\ngg_r &lt;- ggplot(data = avg_r, mapping = aes(x = year, y = mean_wt, color = species)) \n\n# Add the line geometry\ngg_r +\n  geom_line()\n\n\n\n\n\n\nCreate the top level of the graph and assign it to a variable. Then–separately–add a line geometry.\n\n# Create graph\ngg_py = p9.ggplot(data = avg_py, mapping = p9.aes(x = \"year\", y = \"mean_wt\", color = \"species\"))\n\n# Add the line geometry\n(gg_py +\n    p9.geom_line())\n\n&lt;Figure Size: (1280 x 960)&gt;"
  },
  {
    "objectID": "viz_gg.html#customizing-themes",
    "href": "viz_gg.html#customizing-themes",
    "title": "Visualizing Data",
    "section": "Customizing Themes",
    "text": "Customizing Themes\nOnce you have a graph that has the desired content mapped to various aesthetics and uses the geometry that you want, it’s time to dive into the optional fourth component of grammar of graphics plots: themes! All plot format components from the size of the font in the axes to the gridline width are controlled by theme elements.\nTo emphasize the theme modification examples below, let’s assign all components of the above graph into a new variable/object.\n\nR Project RPython Python\n\n\n\n# Make the line graph object\nline_r &lt;- gg_r +\n  geom_line()\n\n\n\n\n# Make the line graph variable\nline_py = gg_py + p9.geom_line()\n\n\n\n\n\nBuilt-In Themes\nTo begin, plotnine/ggplot2 both come with pre-built themes that change a swath of theme elements all at once. If one of these fits your visualization needs then you don’t need to worry about customizing the nitty gritty yourself which can be a real time-saver.\nLet’s add the built-in ‘black and white’ theme to our existing graph using the theme_bw function.\n\nR Project RPython Python\n\n\n\n# Add the black and white theme\nline_r + \n  theme_bw()\n\n\n\n\n\n\n\n# Add the black and white theme\n(line_py + \n   p9.theme_bw())\n\n&lt;Figure Size: (1280 x 960)&gt;\n\n\n\n\n\n\n\n\n\n\nFully Custom Themes\nIf we’d rather, we can use the theme function and manually specify particular elements to change ourselves! Each element requires a helper function that matches the category of element beind edited. For instance, text elements get changed with element_text() while line elements with element_line. When we want to remove an element we can use element_blank. Let’s increase the font size for our axis tick labels and titles.\nWe’ll also use the labs function to customize our axis titles slightly.\n\nR Project RPython Python\n\n\nNote that the theme arguments use periods (.) between words.\n\n# Customize theme more fully\nline_r + \n  labs(x = \"Year\", y = \"Average Weight (g)\") +\n  theme(panel.background = element_blank(),\n        axis.line = element_line(color = \"black\"),\n        axis.title = element_text(size = 18),\n        axis.text = element_text(size = 14))\n\n\n\n\n\n\nNote that the theme arguments use underscores (_) between words to be consistent with Python syntax.\n\n# Customize theme more fully\n(line_py + \n   p9.labs(x = \"Year\", y = \"Average Weight (g)\") +\n   p9.theme(panel_background = p9.element_blank(),\n            axis_line = p9.element_line(color = \"black\"),\n            axis_title = p9.element_text(size = 18),\n            axis_text = p9.element_text(size = 14)))\n\n&lt;Figure Size: (1280 x 960)&gt;"
  },
  {
    "objectID": "viz_gg.html#continuing-to-explore",
    "href": "viz_gg.html#continuing-to-explore",
    "title": "Visualizing Data",
    "section": "Continuing to Explore",
    "text": "Continuing to Explore\nThis lesson was designed to showcase the similarity between Python Python and R Project R, not to provide an exhaustive primer on all things ggplot. There are a lot of really cool graphs you can make with these tools and hopefully this website makes you feel better prepared to translate the knowledge you have from one language into the other!\nIf you are new to ggplot, I recommend searching out “faceting” graphs in particular as this can be a particularly powerful tool when you have many groups within your data variable/object.\n\nAdditional Resources\n\nR Project R – NCEAS Scientific Computing team has a nice Tidyverse Workshop with a particular emphasis on ggplot2\nPython Python – The Carpentries covers plotnine in their ‘Python for Ecologists’ lesson\nR Project R – The Carpentries also covers ggplot2 in their ‘R for Ecologists’ lesson"
  },
  {
    "objectID": "automata.html",
    "href": "automata.html",
    "title": "Workflow Automation",
    "section": "",
    "text": "Often we want to perform some set of operations repeatedly across a known number of iterations. For example, maybe we want to subset a given data file into a separate variable/object by month of data collection and export the resulting file as a CSV. We could simply copy/paste our ‘subset and export’ code as many times as needed but this can be error-prone. Also, it is cumbersome to manually update all copies of the relevant code when you identify a possible improvement.\nOne code solution to this is to automate the workflow using for loops (casually referred to more simply as just “loops”). The syntax of Python Python and R Project R is very similar for loops–likely because this is such a fundamental operation to any coding language!\n\nR Project RPython Python\n\n\nMake a simple object to demonstrate loops.\n\n# Make a vector of animal types\nzoo_r &lt;- c(\"lion\", \"tiger\", \"crocodile\", \"vulture\", \"hippo\")\n\n# Check that out\nzoo_r\n\n[1] \"lion\"      \"tiger\"     \"crocodile\" \"vulture\"   \"hippo\"    \n\n\n\n\nMake a simple variable to demonstrate loops.\n\n# Make a list of animal types\nzoo_py = [\"lion\", \"tiger\", \"crocodile\", \"vulture\", \"hippo\"]\n\n# Check that out\nzoo_py\n\n['lion', 'tiger', 'crocodile', 'vulture', 'hippo']\n\n\n\n\n\nWith this simple variable/object in-hand we can now demonstrate the core facets of loops.\n\n\nLoops (in either language) require a few core components in order to work properly:\n\nfor statement – defines the start of the loop-definition component\n“Loop Variable/Object” – essentially a placeholder variable/object whose value will change with each iteration of the loop\nin statement – relates loop variable/object to set of list/vector to iterate across\nlist/vector to iterate across – set of values to iterate across\nActual workflow! – operations to perform on each iteration of the loop\n\nTo see in this syntax in action we’ll use a simple loop that prints each animal type in the list/vector we created above.\n\nR Project RPython Python\n\n\nIn R, the for statement requires parentheses around the loop object, the in statement, and the vector to iterate across. The operation(s) performed in each iteration must be wrapped in curly braces ({...}).\nWhen the code reaches the closing curly brace it returns to the top of the workflow and begins again with the next element of the provided vector.\n\n# For each animal in the zoo\nfor(animal in zoo_r){\n  \n  # Print its name\n  print(animal)\n  \n}\n\n[1] \"lion\"\n[1] \"tiger\"\n[1] \"crocodile\"\n[1] \"vulture\"\n[1] \"hippo\"\n\n\nNote that when we are done the loop object still exists and is set to the last element of the vector we iterated across.\n\n# Check current value of `animal` object\nanimal\n\n[1] \"hippo\"\n\n\n\n\nIn Python, the for statement, loop variable, in statement, and list to iterate across do not use parentheses but the end of the line requires a colon :. The operation(s) performed in each iteration must be indentened one level (i.e., press “tab” once or “space” four times).\nWhen the code reaches the end of the indented lines it returns to the top of the workflow and begins again with the next item of the provided list.\n\n# For each animal in the zoo\nfor animal in zoo_py:\n  # Print its name\n  print(animal)\n\nlion\ntiger\ncrocodile\nvulture\nhippo\n\n\nNote that when we are done the loop variable still exists and is set to the last item of the list we iterated across.\n\n# Check current value of `animal` variable\nanimal\n\n'hippo'\n\n\n\n\n\n\n\n\nWe can also build conditional statements into a loop to create a loop that can flexibly handle different outcomes. We have discussed conditional operators elsewhere so we’ll only explain the parts of loop conditionals that we haven’t already discussed. To demonstrate, we can loop across a set of numbers and use conditionals to print whether the values are greater/less than or equal to zero.\nIn the example below we’ll use three new statements if, else if and else. Each condition only performs its operation when its condition is met (i.e., returns True/TRUE).\n\nR Project RPython Python\n\n\nThese three statements all have similar syntax to the for statement in that they evaluate something in parentheses and then perform some operation(s) in curly braces. They do differ slightly in context however:\n\nif can only be used first (or in cases where there is only if and else)\nelse if can only be used after if (or after another else if) and allows for specifying another condition.\nelse can only be used at the end; catches only cases that don’t meet one of the prior conditions\n\n\n# Loop across numbers\nfor(j in c(-2, -1, 0, 1, 2)){\n  \n  # If less than 0\n  if(j &lt; 0){ \n    print(paste(j, \"is negative\")) \n    }\n  \n  # If greater than 0\n  else if(j &gt; 0){\n    print(paste(j, \"is positive\"))\n  }\n  \n  # If neither of those, then it must be 0!\n  else { \n    print(paste(j, \"is zero!\"))\n    }\n}\n\n[1] \"-2 is negative\"\n[1] \"-1 is negative\"\n[1] \"0 is zero!\"\n[1] \"1 is positive\"\n[1] \"2 is positive\"\n\n\nNote that to get the message to print correctly we needed to wrap a paste function in print to assemble multiple things into a single object.\n\n\nThese three statements all have similar syntax to the for statement in that they evaluate something before a colon and then perform some operation(s) after that colon. They do differ slightly in context however:\n\nif can only be used first (or in cases where there is only if and else)\nelif can only be used after if (or after another elif) and allows for specifying another condition.\nelse can only be used at the end; catches only cases that don’t meet one of the prior conditions\n\n\n# Loop across numbers\nfor k in [-2, -1, 0, 1, 2]:\n  \n  # If less than 0\n  if k &lt; 0: \n    print(str(k) + \" is negative\")\n    \n  # If greater than 0\n  elif k &gt; 0:\n    print(str(k) + \" is positive\")\n  \n  # If neither of those, then it must be 0!\n  else:\n    print(str(k) + \" is zero!\")\n\n-2 is negative\n-1 is negative\n0 is zero!\n1 is positive\n2 is positive\n\n\nNote that to get the message to print correctly we needed to coerce the loop variable into type string (using the str function)."
  },
  {
    "objectID": "automata.html#loops",
    "href": "automata.html#loops",
    "title": "Workflow Automation",
    "section": "",
    "text": "Often we want to perform some set of operations repeatedly across a known number of iterations. For example, maybe we want to subset a given data file into a separate variable/object by month of data collection and export the resulting file as a CSV. We could simply copy/paste our ‘subset and export’ code as many times as needed but this can be error-prone. Also, it is cumbersome to manually update all copies of the relevant code when you identify a possible improvement.\nOne code solution to this is to automate the workflow using for loops (casually referred to more simply as just “loops”). The syntax of Python Python and R Project R is very similar for loops–likely because this is such a fundamental operation to any coding language!\n\nR Project RPython Python\n\n\nMake a simple object to demonstrate loops.\n\n# Make a vector of animal types\nzoo_r &lt;- c(\"lion\", \"tiger\", \"crocodile\", \"vulture\", \"hippo\")\n\n# Check that out\nzoo_r\n\n[1] \"lion\"      \"tiger\"     \"crocodile\" \"vulture\"   \"hippo\"    \n\n\n\n\nMake a simple variable to demonstrate loops.\n\n# Make a list of animal types\nzoo_py = [\"lion\", \"tiger\", \"crocodile\", \"vulture\", \"hippo\"]\n\n# Check that out\nzoo_py\n\n['lion', 'tiger', 'crocodile', 'vulture', 'hippo']\n\n\n\n\n\nWith this simple variable/object in-hand we can now demonstrate the core facets of loops.\n\n\nLoops (in either language) require a few core components in order to work properly:\n\nfor statement – defines the start of the loop-definition component\n“Loop Variable/Object” – essentially a placeholder variable/object whose value will change with each iteration of the loop\nin statement – relates loop variable/object to set of list/vector to iterate across\nlist/vector to iterate across – set of values to iterate across\nActual workflow! – operations to perform on each iteration of the loop\n\nTo see in this syntax in action we’ll use a simple loop that prints each animal type in the list/vector we created above.\n\nR Project RPython Python\n\n\nIn R, the for statement requires parentheses around the loop object, the in statement, and the vector to iterate across. The operation(s) performed in each iteration must be wrapped in curly braces ({...}).\nWhen the code reaches the closing curly brace it returns to the top of the workflow and begins again with the next element of the provided vector.\n\n# For each animal in the zoo\nfor(animal in zoo_r){\n  \n  # Print its name\n  print(animal)\n  \n}\n\n[1] \"lion\"\n[1] \"tiger\"\n[1] \"crocodile\"\n[1] \"vulture\"\n[1] \"hippo\"\n\n\nNote that when we are done the loop object still exists and is set to the last element of the vector we iterated across.\n\n# Check current value of `animal` object\nanimal\n\n[1] \"hippo\"\n\n\n\n\nIn Python, the for statement, loop variable, in statement, and list to iterate across do not use parentheses but the end of the line requires a colon :. The operation(s) performed in each iteration must be indentened one level (i.e., press “tab” once or “space” four times).\nWhen the code reaches the end of the indented lines it returns to the top of the workflow and begins again with the next item of the provided list.\n\n# For each animal in the zoo\nfor animal in zoo_py:\n  # Print its name\n  print(animal)\n\nlion\ntiger\ncrocodile\nvulture\nhippo\n\n\nNote that when we are done the loop variable still exists and is set to the last item of the list we iterated across.\n\n# Check current value of `animal` variable\nanimal\n\n'hippo'\n\n\n\n\n\n\n\n\nWe can also build conditional statements into a loop to create a loop that can flexibly handle different outcomes. We have discussed conditional operators elsewhere so we’ll only explain the parts of loop conditionals that we haven’t already discussed. To demonstrate, we can loop across a set of numbers and use conditionals to print whether the values are greater/less than or equal to zero.\nIn the example below we’ll use three new statements if, else if and else. Each condition only performs its operation when its condition is met (i.e., returns True/TRUE).\n\nR Project RPython Python\n\n\nThese three statements all have similar syntax to the for statement in that they evaluate something in parentheses and then perform some operation(s) in curly braces. They do differ slightly in context however:\n\nif can only be used first (or in cases where there is only if and else)\nelse if can only be used after if (or after another else if) and allows for specifying another condition.\nelse can only be used at the end; catches only cases that don’t meet one of the prior conditions\n\n\n# Loop across numbers\nfor(j in c(-2, -1, 0, 1, 2)){\n  \n  # If less than 0\n  if(j &lt; 0){ \n    print(paste(j, \"is negative\")) \n    }\n  \n  # If greater than 0\n  else if(j &gt; 0){\n    print(paste(j, \"is positive\"))\n  }\n  \n  # If neither of those, then it must be 0!\n  else { \n    print(paste(j, \"is zero!\"))\n    }\n}\n\n[1] \"-2 is negative\"\n[1] \"-1 is negative\"\n[1] \"0 is zero!\"\n[1] \"1 is positive\"\n[1] \"2 is positive\"\n\n\nNote that to get the message to print correctly we needed to wrap a paste function in print to assemble multiple things into a single object.\n\n\nThese three statements all have similar syntax to the for statement in that they evaluate something before a colon and then perform some operation(s) after that colon. They do differ slightly in context however:\n\nif can only be used first (or in cases where there is only if and else)\nelif can only be used after if (or after another elif) and allows for specifying another condition.\nelse can only be used at the end; catches only cases that don’t meet one of the prior conditions\n\n\n# Loop across numbers\nfor k in [-2, -1, 0, 1, 2]:\n  \n  # If less than 0\n  if k &lt; 0: \n    print(str(k) + \" is negative\")\n    \n  # If greater than 0\n  elif k &gt; 0:\n    print(str(k) + \" is positive\")\n  \n  # If neither of those, then it must be 0!\n  else:\n    print(str(k) + \" is zero!\")\n\n-2 is negative\n-1 is negative\n0 is zero!\n1 is positive\n2 is positive\n\n\nNote that to get the message to print correctly we needed to coerce the loop variable into type string (using the str function)."
  },
  {
    "objectID": "automata.html#custom-functions",
    "href": "automata.html#custom-functions",
    "title": "Workflow Automation",
    "section": "“Custom” Functions",
    "text": "“Custom” Functions\nLoops are a really powerful tool but they are limited in some ways. Sometimes we want to do a task once per project but only use it once in each instance. Such an operation is certainly “repeated” but not really the same context in which a loop makes sense. We can create reusable modular code to fit these circumstances by writing our own custom functions–“custom” in the sense that we write them ourselves rather than load them from a particular library.\nLet’s write a simple function in both languages that simply multiplies two arguments by one another and returns the result.\n\nR Project RPython Python\n\n\nGenerating a function in R shares some syntax elements with loops and conditional statements! In this case we use the function function to preserve our work as a function, then provide any needed arguments in parentheses, and end with curly braces with the operation(s) performed by the function inside. If the function produces something that we want to give back to the user, we need to specify that with the return function.\n\n# Multiplication function\nmult_r &lt;- function(p, q){\n  \n  # Multiply the two values\n  result_r &lt;- p * q\n  \n  # Return that\n  return(result_r)\n}\n\n# Once defined, we can invoke the function like we would any other\nmult_r(p = 2, q = 5)\n\n[1] 10\n\n\n\n\nGenerating a function in Python shares some syntax elements with loops and conditional statements! In this case we use the def statement then provide the name and–parenthetically–any needed arguments for our new function. If the function produces something that we want to give back to the user, we need to specify that by using the return statement.\n\n# Multiplication function\ndef mult_py(n, i):\n  # Add docstrings for later use (see below)\n  \"\"\"\n  Multiply two values by one another.\n  \n  n -- First value to multiply\n  i -- Second value to multiply\n  \"\"\"\n  \n  # Multiply the two values\n  result_py = n * i\n  \n  # Return them\n  return result_py\n\n# Once defined, we can invoke the function like we would any other\nmult_py(n = 2, i = 5)\n\n10\n\n\n\n\n\n\nFunction Documentation\nOne component of custom functions to be aware of is their somewhat variable documentation. “Official” functions tend to be really well documented but custom functions have no required documentation. However, there are some best practices that we can try to follow ourselves to make life as easy as possible for people trying to intuit our functions’ purposes (including ourselves in the future!).\n\nR Project RPython Python\n\n\nR contains no native mode of specifying function documentation! While there are tools to formalize this when functions are part of a formal package (see roxygen2 formatting) our custom functions cannot include documentation. That said, it is still good practice to include plain-language comment lines that describe the function’s operations even when they will only be visible where the function is defined.\nNote that the docstring R package simulates Python-style docstrings for R functions but is not part of “base” R.\n\n\nPython custom functions allow us to specify triple quoted (\"\"\"...\"\"\") documentation of function purpose/arguments known as “docstrings”. When this is supplied, we can use the help function (or append a ? after the function name) to print whatever documentation was included in the function when it was defined.\n\n# Check custom function documentation\nhelp(mult_py)\n\nHelp on function mult_py in module __main__:\n\nmult_py(n, i)\n    Multiply two values by one another.\n    \n    n -- First value to multiply\n    i -- Second value to multiply\n\n\n\n\n\n\n\nFunction Defaults\nSometimes a given argument will often be set to the same value. In cases like this, we can define that as the default of the argument which allows users to not specify that argument at all. When users do specify something for that argument, it overrides the default behavior. All functions (and Python Python methods) with “optional” arguments are using defaults behind the scenes to make those arguments optional.\nWe can define these defaults when we first create a function! Let’s make a simple division function that divides the first argument by the second and sets the default of the second argument to 2.\n\nR Project RPython Python\n\n\nWrite and demonstrate the simple division function.\n\n# Define function\ndiv_r &lt;- function(p, q = 2){\n  \n  # Do division\n  result_r &lt;- p / q\n  \n  # Return that\n  return(result_r)\n}\n\n# Test this function\ndiv_r(p = 10)\n\n[1] 5\n\n\nUse the function again but set the second argument ourselves.\n\n# Specify the second argument\ndiv_r(p = 10, q = 10)\n\n[1] 1\n\n\n\n\nWrite and demonstrate the simple division function.\n\n# Define function\ndef div_py(n, i = 2):\n  # Write function documentation\n  \"\"\"\n  Divide the first value by the second\n  \n  n -- Numerator\n  i -- Denominator\n  \"\"\"\n  \n  # Do division\n  result_py = n / i\n  \n  # Return that\n  return result_py\n\n# Use the function with the default\ndiv_py(n = 10)\n\n5.0\n\n\nUse the function again but set the second argument ourselves.\n\n# Specify the second argument\ndiv_py(n = 10, i = 10)\n\n1.0\n\n\n\n\n\n\n\nFunctions & Conditionals\nJust like loops, we can build conditional statements into our functions to make them more flexible and broadly useful. Let’s combine this with setting default values to demonstrate this effectively.\n\nR Project RPython Python\n\n\nLet’s make a simple addition function and set both arguments to default to NULL. NULL is an R constant that allows us to create an object without assigning any value to it.\nNote that we’re also using the is.null function in our conditional in order to easily assess whether the argument has been left to its default (i.e., set to NULL) or defined.\n\n# Define addition function\nadd_r &lt;- function(p = NULL, q = NULL){\n  \n  # If first argument is missing, set it to 2\n  if(is.null(p) == TRUE){\n    p &lt;- 2\n  }\n  \n  # Do the same for the second argument\n  if(is.null(q) == TRUE){\n    q &lt;- 2\n  }\n  \n  # Sum the two arguments\n  result_r &lt;- p + q\n  \n  # Return that\n  return(result_r)\n}\n\nNow let’s use the function without specifying either argument.\n\n# Use the function\nadd_r()\n\n[1] 4\n\n\n\n\nLet’s make a simple addition function and set both arguments to default to None. None is a Python constant that allows us to create a variable without assigning any value to it.\nNote that we’re also using the is statement in our conditional (in this case it is equivalent to `==``).\n\n# Define addition function\ndef add_py(n = None, i = None):\n  # Add documentation\n  \"\"\"Add two values (`n` and `i`)\"\"\"\n\n  # If first argument is missing, set it to 2\n  if n is None:\n    n = 2\n\n  # Do the same for the second argument\n  if i is None:\n    i = 2\n  \n  # Sum the two arguments\n  result_py = n + i\n  \n  # Return that\n  return result_py\n\nNow let’s use the function without specifying either argument.\n\n# Use the function\nadd_py()"
  }
]